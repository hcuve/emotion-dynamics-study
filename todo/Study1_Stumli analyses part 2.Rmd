---
title: "Non Parametric Time Clustering of Face Dynamics"
author: "Helio"
date: "09/04/2021"
output: html_document
---



```{r}
db_of5_coorrelations$video<- NULL

# d2, d4, d8, d7 
max(db_of5$)
db_of5_new<- subset(db_of5, db_of5$timestamp< 6)

db_of5_new$face_action_AVG<- rowMeans(db_of5_new[, c("D2", "D4", "D7", "D8")], na.rm = TRUE)
# db_of5_new$face_action_AVGtest<- (db_of5_new$D2+ db_of5_new$D4+db_of5_new$D7+ db_of5_new$D8)/4

a$mean <- rowMeans(a[,c('high', 'low')], na.rm=TRUE)

distance_correlations<- cor(db_of5_coorrelations)
View(distance_correlations)


db_of5_new%>%
  ggplot(aes(timestamp, face_action_AVG, colour = morph))+
  geom_line(aes(group = video))+
  stat_summary(geom = "line", size = 2)+
  facet_grid(~Dataset)


db_of5_new%>%
  ggplot(aes(timestamp, face_action_AVG, colour = morph))+
  geom_line(aes(group = video))+
  stat_summary(geom = "line", size = 2)+
  facet_grid(Dataset~Emotion)

db_of5_new$morph<- as.factor(db_of5_new$morph)
db_of5_new$morph<- relevel(db_of5_new$morph, ref = "Original")

db_of5_new$Emotion<- as.factor(db_of5_new$Emotion)
db_of5_new$face_unique<- as.factor(db_of5_new$face_unique)

polymodels$avgnull1 <- lmer(log1p(face_action_AVG+.1) ~ (0 + ot1+ot2 |face_unique) + (1| Dataset)+ 
                             (1|face_unique), 
                             # (0 +Dataset | face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = db_of5_new) 
polymodels$poly_orig_full1 
relgrad <- with(polymodels$avgnull1@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

summary(polymodels$avgnull)


polymodels$avgnull2 <- lmer(log1p(face_action_AVG+.1) ~ (0 + ot1+ot2 |face_unique) + (1 | Dataset)+ 
                             # (0+Emotion|face_unique) +
                              (1|face_unique), 
                             # (0 +Dataset | face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = db_of5_new) 

relgrad <- with(polymodels$avgnull2@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))
anova(polymodels$avgnull, polymodels$avgnull1 )


summary(polymodels$avgnull2)
```

```{r}
options(contrasts = c("contr.sum","contr.poly"))
polymodels$avgface <- lmer(log1p(face_action_AVG+.1) ~ morph*Emotion* (ot1+ ot2+ot3)+ (0 + ot1+ot2|face_unique) +
                             (1|face_unique), 
                             # (0 +Dataset | face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = db_of5_new) 

relgrad <- with(polymodels$avgface@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

plot(polymodels$avgface)
qqnorm(resid(polymodels$avgface))
qqline(resid(polymodels$avgface))
summary(polymodels$avgface)
library(MuMIn)
r.squaredGLMM(polymodels$avgface)

# polymodels$avgface1 <- lmer(log1p(face_action_AVG+.1) ~ 
#                               morph+Emotion+ (ot1+ ot2+ot3)+ 
#                               morph:Emotion+ 
#                               morph:(ot1+ ot2+ot3)+
#                               # Emotion:+ 
#                               morph*Emotion*(ot1+ ot2+ot3)+
#                               (0 + ot1+ot2|face_unique) + (1|Dataset)+
#                              (1|face_unique), 
#                              # (0 +Dataset | face_unique),
#                        REML = FALSE,
#                        verbose = TRUE,
#                        data = db_of5_new) 
# 
# polymodels$avgface2 <- lmer(log1p(face_action_AVG+.1) ~ 
#                               morph+Emotion+ (ot1+ ot2+ot3)+ 
#                               (Dataset+morph):Emotion+ 
#                               morph:(ot1+ ot2+ot3)+
#                               # Emotion:+ 
#                               morph:Emotion:(ot1+ ot2+ot3)+ morph:Dataset:(ot1+ ot2+ot3)+
#                               (0 + ot1+ot2|face_unique) + (1|Dataset)+
#                              (1|face_unique), 
#                              # (0 +Dataset | face_unique),
#                        REML = FALSE,
#                        verbose = TRUE,
#                        data = db_of7_new) 




summary(polymodels$avgface2)
anova(polymodels$avgface2)

relgrad <- with(polymodels$avgface2@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))


plot(polymodels$avgface2)
qqnorm(resid(polymodels$avgface2))
qqline(resid(polymodels$avgface2))

polymodels$avgface3 <- lmer(face_action_AVG2 ~ 
                              Dataset*morph*Emotion* (ot1+ ot2+ot3)+ 
                              # (Dataset+morph):Emotion+ 
                              # morph:(ot1+ ot2+ot3)+
                              # # Emotion:+ 
                              # morph:Emotion:(ot1+ ot2+ot3)+ morph:Dataset:(ot1+ ot2+ot3)+
                              (1 + ot1+ot2 |stim_id) + 
                              # (0+ morph|stim_id)+
                             (0+ot3|stim_id),
                             # (0 +Dataset | face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = db_of7_new)

library(psycho)
install.packages("psycho")
install.packages("statnet")
polymodels$avgface3_analyze <- psycho:: analyze(polymodels$avgface3)


summary(polymodels$avgface3)
anova(polymodels$avgface3)
stdCoef.merMod <- function(object) {
  sdy <- sd(getME(object,"y"))
  sdx <- apply(getME(object,"X"), 2, sd)
  sc <- fixef(object)*sdx/sdy
  se.fixef <- coef(summary(object))[,"Std. Error"]
  se <- se.fixef*sdx/sdy
  return(data.frame(stdcoef=sc, stdse=se))
}

stdCoef.merMod(polymodels$avgface3)
db_of7_new%>%
  ggplot(aes(Dataset,face_action_AVG2))+
  stat_summary(geom = 'pointrange')

relgrad <- with(polymodels$avgface3@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

plot(polymodels$avgface3)
anova(polymodels$avgface3)
emmeans::emmeans(polymodels$avgface3, pairwise ~ Emotion, adjust = 'bonf')

emmeans::emmeans(polymodels$avgface3, pairwise ~ Emotion|Dataset, adjust = 'bonf')

emmeans::emmeans(polymodels$avgface3, pairwise ~ Emotion|morph, adjust = 'bonf')


emmeans::emmeans(polymodels$avgface3, pairwise ~ Emotion|ot1, adjust = 'bonf')
```



```{r}
p<- list()
sf = 1 # constant for easily cganging text size

p$graphstyle <-  theme(#base plot theme
  # axis
  axis.line.y = element_line(),
  axis.line.x = element_line(),
  axis.text.x = element_text(size = 15+(sf+.5), family = "sans", colour = "black", hjust = .8), #angle = 45,
  axis.text.y = element_text(size = 15+(sf+.5), family = "sans", colour = "black"),
  #axis.ticks = element_blank(),
  #axis.text.y = element_text(size= 18, family = "Arial Narrow", colour="black"),
  axis.title.y=element_text(size = 16*(sf+.7), margin=margin(0,5,0,0)),
  axis.title.x=element_text(size = 16*(sf+.7), margin=margin(0,5,0,0)),
  
  # strips
  strip.background = element_blank(),
  strip.text.x = element_text(size = 12*(sf+.5),  colour = "black"),
  strip.text.y = element_text(size = 12*(sf+.5),  colour = "black"),
  
  # panel
  # panel.background = element_rect(colour = NA),
  # plot.background = element_rect(colour = NA),
  # panel.border = element_rect(colour = NA),
  # panel.border = element_blank(),
  # panel.grid.major = element_blank(),
  # panel.grid.minor = element_blank(),
  # panel.background = element_blank(),
  
  # legend
  # legend.title = element_text(size = 10*(sf+.3)),
  legend.position = "top",
  legend.direction = "horizontal",
  #legend.key.size = unit(.5, "cm"),
  #legend.text = element_text(size = 10*sf),
  legend.title=element_blank(),
  #legend.text = element_blank(),
  legend.key = element_rect(colour = "transparent", fill="transparent"),
  # text
  text=element_text(size = 16*(sf+.4), family = "sans"))
 

p$graphstyle1 <-  theme(#base plot theme
  axis.line.y = element_blank(),
  axis.line.x = element_blank(),
  strip.text.x = element_text(size = 11*(sf+.5),  colour = "black"),
  strip.text.y = element_text(size = 11*(sf+.5),  colour = "black"),
  panel.border = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  #panel.background = element_rect(fill="transparent"),
  #panel.border = element_rect(fill="transparent"),
   # legend
  #legend.position = "top", 
  #legend.direction = "horizontal",
  #legend.key.size = unit(.5, "cm"),
  #legend.text = element_text(size = 10*sf+.3),
  legend.title = element_text(size = 10*(sf+.3)),
  #legend.key.size = unit(.5, "cm"),
  #legend.text = element_text(size = 10*sf),
  #legend.title=element_blank(),
  #legend.text = element_blank(),
  text=element_text(size = 14, family = "sans"),
  axis.text.x = element_text(size = 14, family = "sans", colour = "black",),
  axis.text.y = element_text(size = 14, family = "sans", colour = "black"),
  #axis.ticks = element_blank(),
  # strip shades (reco rectagles)
  strip.background = element_blank(),
  #axis.text.y = element_text(size= 18, family = "Arial Narrow", colour="black"),
  axis.title.y=element_text(size = 14*(sf+.5), margin=margin(0,5,0,0)),
  axis.title.x=element_text(size = 14*(sf+.5), margin=margin(0,5,0,0)),
  legend.key = element_rect(colour = "transparent", fill="transparent"))



```


```{r}

polynomialfits<-
  db_of5_new%>%
    # subset(Dataset != "JEFFE")%>%
    ggplot(aes(timestamp, fit_new, colour = Emotion))+
    geom_line(aes(group = video))+
       # geom_line(aes(group = video, y = face_action_AVG), linetype = 'dashed')+
      facet_grid(Dataset~morph)+
  xlab("Time (s)")+
  ylab("Face action change (pix)")



db_of5_new$Dat<- if_else(db_of5_new$Dataset == "ADFES", "High prototypicality", "Low prototypicality")
db_of7_new %>%
  group_by(Emotion, Em, Dataset, Dat, morph,video)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  
  ggplot(aes(Em, face_action_AVG, colour = Emotion))+
  geom_boxplot()+
  geom_jitter()+
  facet_grid(~Dat)+
  xlab("Emotion")+
  ylab("Average change (pix)")+
  p$graphstyle+
  scale_color_brewer(palette = "Dark2")+
  theme(axis.text.x = element_text(size = 16),
        axis.text.y = element_text(size = 16),
        axis.title.y = element_text(size = 20),
        axis.title.x = element_text(size = 20),
        legend.position = "top")


```



```{r}
drop1(polymodels$avgface1)
library(MuMIn)
r.squaredGLMM(polymodels$avgface1)

anova(polymodels$avgface1)

polymodels$avgface1_step <- step(polymodels$avgface1)

polymodels$avgface1_step 

# to do
# run the boostrap version and the analyse over night



db_of5_new$fit<- predict(polymodels$avgface1, re.form = NULL)
db_of5_new%>%
  ggplot(aes(timestamp, log1p(face_action_AVG+.1)))+
  # geom_line(aes(group = video))+
   geom_line(aes(y = fit, group = video))+
  stat_summary(geom = 'line')+
  stat_summary(aes(y = fit), geom = 'line', size = 1.5, colour = 'red')+
  facet_grid(~Dataset)



summary(polymodels$avgface2)

db_of5_new$fit2<- predict(polymodels$avgface2, re.form = NULL)

db_of5_new%>%
  ggplot(aes(timestamp, fit, colour = morph))+
  geom_line(aes(group = video))+
   # geom_line(aes(y = fit, group = video))+
  stat_summary(geom = 'line')+
  stat_summary(aes(y = fit), geom = 'line', size = 1.5, colour = 'red')+
  facet_grid(~Dataset)
db_of5_new%>%
  ggplot(aes(timestamp, fit2, colour = Emotion))+
  geom_line(aes(group = video))+
   # geom_line(aes(y = fit, group = video))+
  stat_summary(geom = 'line')+
  stat_summary(aes(y = fit2), geom = 'line', size = 1.5, colour = 'red')+
  facet_grid(morph~Dataset)




```


Boostraps
```{r}
# boostrap

polymodels$avgface1_boot <- bootMer(polymodels$avgface1, FUN = fixef, nsim = 1000, 
                                                  seed = 444, use.u = FALSE,
                                                  type="parametric")



# boot::boot.ci(polymodels$morph_emotion1_boot,type="perc",index=3)




```

# model with dataset

```{r}
polymodels$avgface2_boot <- bootMer(polymodels$avgface2, FUN = fixef, nsim = 500, 
                                                  seed = 444, use.u = FALSE,
                                                  type="parametric")


boot::boot.ci(polymodels$morph_emotion1_boot,type="perc",index=3)

avgface1results_analyze<- analyze(polymodels$avgface1, CI = 95)
# print(results)



avgface2results_analyze<- analyze(polymodels$avgface3, CI = 95)
# print(results)

```

Analyse models

```{r}

avgface1results_analyze<- analyze(polymodels$avgface1, CI = 95)
# print(results)

```

```{r}

avgface2results_analyze<- analyze(polymodels$avgface2, CI = 95)
# print(results)

```



Model of dataset
```{r}
# now run the dataset version, withouth emotion, and then the dataset dearetelly by emotion

polymodels$avgface_jeffe <- lmer(log1p(face_action_AVG+.1) ~ morph+Emotion+ (ot1+ ot2+ot3)+ morph*Emotion+ 
                              morph*(ot1+ ot2+ot3)+
                              # Emotion:+ 
                              morph*Emotion*(ot1+ ot2+ot3)+
                              (0 + ot1+ot2|face_unique) +
                             (1|face_unique), 
                             # (0 +Dataset | face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = subset(db_of5_new, db_of5_new$Dataset == 'JEFFE')) 

summary(polymodels$avgface_jeffe)

relgrad <- with(polymodels$avgface@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

plot(polymodels$avgface_jeffe)
qqnorm(resid(polymodels$avgface_jeffe))
qqline(resid(polymodels$avgface_jeffe))

drop1(polymodels$avgface_jeffe)
library(MuMIn)
r.squaredGLMM(polymodels$avgface_jeffe)

anova(polymodels$avgface_jeffe)

polymodels$avgface1_step_jeffe <- step(polymodels$avgface_jeffe)

polymodels$avgface1_step_jeffe


```


```{r}

polymodels$avgface_ADFES <- lmer(log1p(face_action_AVG+.1) ~ morph+Emotion+ (ot1+ ot2+ot3)+ morph*Emotion+ 
                              morph*(ot1+ ot2+ot3)+
                              # Emotion:+ 
                              morph*Emotion*(ot1+ ot2+ot3)+
                              (0 + ot1+ot2|face_unique) +
                             (1|face_unique),
                       REML = FALSE,
                       verbose = TRUE,
                       data = subset(db_of5_new, db_of5_new$Dataset == 'ADFES')) 

summary(polymodels$avgface_ADFES)

relgrad <- with(polymodels$avgface_jeffe@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

plot(polymodels$avgface_ADFES)
qqnorm(resid(polymodels$avgface_ADFES))
qqline(resid(polymodels$avgface_ADFES))

drop1(polymodels$avgface_ADFES)
library(MuMIn)
r.squaredGLMM(polymodels$avgface_ADFES)
r.squaredGLMM(polymodels$avgface_ADFES)

library(sjstats)
r2(polymodels$avgface_ADFES, n = NULL)
anova(polymodels$avgface_ADFES)

install.packages("r2glmm")
library(r2glmm)
tab_model(polymodels$avgface_ADFES)

polymodels$avgface1_step_ADFES <- step(polymodels$avgface_ADFES)

polymodels$avgface1_step_ADFES




```


okat test specific time clusters for ace average motion

```{r}
db_of7_new%>%
  ggplot(aes(timestamp, face_action_AVG2, colour = morph))+
  # geom_smooth()
  geom_line(aes(group = video), alpha = .2)+
  stat_summary(geom = 'line', size = 2)+
  facet_grid(Dataset~Emotion)

```


```{r}
library(itsadug)
library(tidyverse)
db_of5_new$timestamp
db_of6_new<-  db_of5_new%>%
  group_by(filename)%>%
  mutate(timebin = timeBins(timestamp, binsize = .15, pos = 0))

max(db_of6_new$timebin)


# install.packages("trinker")
# library(trink)

# aggregate by timebin

db_of7_new <- db_of6_new%>%
  group_by(filename, timebin, morph, Emotion, Dataset, video, face_unique)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)

# plot by timebin

db_of7_new%>%
  ggplot(aes(timebin, face_action_AVG, colour = morph))+
  stat_summary(geom = "line", size = 2)+
  geom_line(aes(group = video), alpha = .2)+
  facet_grid(~Dataset)+
  theme_minimal()


```



```{r}
db_of7_new$VideoType_contrast<- if_else(db_of7_new$morph == "Morph", -.5, +.5)


# create a vector with the timebins
timebinout_avg<- unique(db_of7_new$timebin)

# make sure face is a factor
db_of7_new$face_unique<- as.factor(db_of7_new$face_unique)
#findout how mny timebins do we have
db_of7_new%>%
  group_by(filename)%>%
  summarise(n = n()) #== 40

# create an empty dataframe that will hold the information from each test
test.data_avgface<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg<- list()
# lmer


i = 15 # currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore

# i = 2

i=2

table(db_of7_new$VideoType_contrast)
unique(db_of7_new$face_unique)
test.data_avgface$cov<- as.character(test.data_avgface$cov)
View(db_of7_new)

for (i in 1:length(timebinout_avg)) {
  testresults_avg<- lmer(log1p(face_action_AVG2+.1) ~ VideoType_contrast + (1 |face_unique) ,
                           # (1| Dataset),
                         data = db_of7_new[db_of7_new$timebin == timebinout_avg[i],])
  
   summarytest_avg<- summary(testresults_avg)
   
   test.data_avgface[i,1]<-timebinout_avg[i]
  test.data_avgface[i,2]<- summarytest_avg[["coefficients"]][2,1]
   test.data_avgface[i,3]<-summarytest_avg[["coefficients"]][2,4]
   test.data_avgface[i,4]<-summarytest_avg[["coefficients"]][2,5]
   test.data[i,5]<- as.character(ifelse(length(summarytest_avg$optinfo$conv$lme4$message) == 0,'pass',
                             summarytest_avg$optinfo$conv$lme4$message))
   
   print(i)
}

View(   test.data_avgface)

# test.data_avgface_96<- data.frame(timebins= rep(NA, 96), Estimate= rep(NA, 96), t=rep(NA, 96), p=rep(NA, 96), cov= as.character(rep(NA,96)) )

# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_96<- list()

 unique(db_of7_new$VideoType_contrast) # morph == -.5, original .5
# timebinout_avg96<- unique(db_of7_new $timestamp)
# for (i in 1:length(timebinout_avg)) {
#   testresults_avg<- lmer(log1p(face_action_AVG +.1) ~ morph + (1 |face_unique) + (1| Dataset),
#                       data = db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
# 
#   # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
#   #                     data = db_of8 [db_of8$timebin == timebinout[i] & db_of8$Dataset !="JEFFE",])
#    summarytest_avg<- summary(testresults_avg)
#    
#    test.data_avgface[i,1]<-timebinout_avg[i]
#   test.data_avgface[i,2]<- summarytest_avg[["coefficients"]][2,1]
#    test.data_avgface[i,3]<-summarytest_avg[["coefficients"]][2,4]
#    test.data_avgface[i,4]<-summarytest_avg[["coefficients"]][2,5]
#    # test.data[i,5]<- testresults@optinfo$val
#    print(i)
#    }

# now sum adjancet timebins
# create a flag for significance
# test.data_avgface$cluster<- if_else(test.data_avgface$p< .05, TRUE, FALSE)
test.data_avgface<- test.data_avgface%>%
  mutate(cluster_log = if_else(test.data_avgface$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_avgface)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
test.data_avgface<- test.data_avgface%>%
  mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
  mutate(p_holm = p.adjust(p, method = "bonf"))





timebin_shuff<- unique(db_of7_new$timebin)

 # create a random arrangment of labels for oroginal and morpj
 
 
  testtemp%>%
    group_by(morph)%>%
    summarise(n= n())
  

 library(permute)

nsim = 1:100 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )
View(simulated_clusters)


timebin_random<- unique(db_of7_new$timebin)




# create random labels

table(is.na(db_of7_new$morph1))
install.packages("permute")
install.packages('foreach') 
library(permute)
library(foreach)
i = 1 # remember to always rezero it
# b = 34

seed = 444

 simulated_clusters$cov<- as.character( simulated_clusters$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 unique(db_of7_new$VideoType_contrast) # morph == -.5, original .5
 
for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {
    # tryCatch({
    #shuffle the predictor
    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each = 3840)), replace = FALSE) 
    # remeber to use sample withouth replacement to make sure the quantities remain the same in each level of the predictor

        #run the model on the current time bin and simulation sumber
        lmer_bin_random  <- lmer(log1p(face_action_AVG2+.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                                 # (1| Dataset),
                      data = subset(db_of7_new, db_of7_new$timebin == timebin_random[b]))

        #store results from the somularion
        # View(simulated_clusters)
            lmer_bin_random_summary<- summary(lmer_bin_random)
            simulated_clusters[i,1]<- timebin_random[b] #save the exact value of time bin
            simulated_clusters[i,2]<- lmer_bin_random_summary[["coefficients"]][2,1] # save the stimate
            simulated_clusters[i,3]<-lmer_bin_random_summary[["coefficients"]][2,4] # t statistic
            simulated_clusters[i,4]<-lmer_bin_random_summary[["coefficients"]][2,5] # p value
            simulated_clusters[i,6]<- nsim[s] #store simulation ount
            simulated_clusters[i,5] <- ifelse(length(lmer_bin_random_summary$optinfo$conv$lme4$message) != 0,
                                               lmer_bin_random_summary$optinfo$conv$lme4$message, 'pass')
              
        # update so that we can store things properly in the big dataset next time
    

     i = i+1
       # 

  }
 }
 
 # Now do clustering of shuffled data, and s
     View(simulated_clusters)
     table(simulated_clusters$cov == 'pass') # check how many convrgence errors we have
#       4489/(4489+35511)
     77/(77+  3923)
     simulated_clusters%>%
       ggplot(aes(t))+
       geom_histogram()
     
       simulated_clusters%>%
       ggplot(aes(timebins, t))+
         # geom_smooth()
        stat_summary(geom = 'line')
         
       geom_histogram()
     
# [1] 0.112225
    simulated_clusters$relgrad<- as.numeric(substr(simulated_clusters$cov,43, 48)) #extract the convergence tol
    simulated_clusters$relgrad_velow<- if_else(simulated_clusters$relgrad< .02, TRUE, FALSE)
     table(simulated_clusters$relgrad_velow)
     207/(207+4280) ~ 5 %
     (4489-4280)/(4489+35511) #so the total non convergence rate is .005 *100 == 0.5%
     
    ### Cluster again on the shuffled data###
     
     # & simulated_clusters$timebins == nbins[b] do we need ti grouo it by timebine
     # for each simulation, cluster timebins
      sum_cluster_sim <- simulated_clusters %>% 
        # filter( simulated_clusters$sim == nsim[s])%>% # pick the current simulation
        arrange(sim, timebins)%>%
        group_by(sim)%>%
        mutate(cluster_shuffle_log = if_else(p < .05, TRUE, FALSE))%>% # create a logical highlighticng signiiant
        # bins
        mutate(Direction = if_else(t > 0 & cluster_shuffle_log == TRUE, "Positive", 
                                  if_else(t < 0 & cluster_shuffle_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # filter(!is.na(Direction))%>% 
        #significant because later we will need to group by this
      #group_by(cluster_shuffle_log,Direction)%>%
      # below we are creating a counter that that counts only the significant bins, separatelly by whether their are positive or
        #negative to cinfirm if it works 
        group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_countershuffle  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(sim, cluster_countershuffle)%>%
      mutate(t_sum_shuffle_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_shuffle_dir = if_else(cluster_shuffle_log == TRUE, t_sum_shuffle_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE),
                                      cluster_countershuffle, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE), 
                                      t_sum_shuffle_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))%>%
        
        #fill it
      fill(MaxCLust_label, .direction = "updown")%>%
      fill(MaxCLust_value, .direction = "updown")%>%
      fill(MaxCLust_direction, .direction = "updown")
      
      View(sum_cluster_sim)
      # test sim 4 that had a probpem
      sim4<- subset(sum_cluster_sim, sum_cluster_sim$sim == 4)
      View(sim4)
    unique(sum_cluster_sim$MaxCLust_value) 
    
     # a few warnings - invalid factor NA levels = 
 # ma NA = because there is no max that survived sigificance
    
    
    # DO some visualisation
    sum_cluster_sim %>%
      ggplot(aes(MaxCLust_value))+
      geom_histogram(fill = 'blue', alpha = .5)+
      geom_vline(xintercept = 23)
    
```

Compare simulated data with original model
```{r}
simulattion_vs_data<- left_join(sum_cluster_sim, test.data_avgface, by = "timebins")
View(simulattion_vs_data)  


simulattion_vs_data%>%
  mutate(t.obs_sign = if_else(p.y < .05, t.y, NULL))%>%
# simulattion_vs_data %>%
  # ggplot(aes(t.x))+
  ggplot(aes(MaxCLust_value.x))+
  geom_histogram()+
  # geom_histogram(aes(x = t.x))+
  geom_vline(aes(xintercept = t_sum_dir, colour = as.factor(cluster_counter)))+
  geom_vline(aes(xintercept = t.obs_sign))+
  geom_vline(xintercept = -2.374, size = 3, linetype = "dashed")


simulattion_vs_data%>%
  ggplot(aes(timebins, t.x))+
  stat_summary(geom= 'line')+
  stat_summary(aes(y = t.y), geom = 'line')
  
  
  ggplot(aes(t))+
  geom_histogram(fill = 'blue', alpha = .5)

sum_cluster_sim 
mergedtest<- full_join(sum_cluster_sim, test.data_avgface, by = "timebins")

View(mergedtest)

View(test.data_avgface)
View(sum_cluster_sim)

# calculation of propabilities
# p-value for the cluster
# p value is calculated by taking the number of times the sum t statistic was greater than the observed one
simulattion_vs_data<- simulattion_vs_data%>%
    ungroup()%>%
      # group_by(sim,Direction.y) %>%
  fill(MaxCLust_value.y, .direction = "down")%>%
  mutate(MAX_clust_count= if_else(is.na(MaxCLust_value.x) == TRUE,0, 
                                  if_else(abs(!is.na(MaxCLust_value.x))> abs(!is.na(MaxCLust_value.y)), 1, 0)))
View(simulattion_vs_data)

simulattion_vs_data%>%
  ungroup()%>%
  # group_by()
  summarise(p = sum(MAX_clust_count)/n())

plots_of<- list()
plots_of$fullmodel_plot <-
simulattion_vs_data%>%
  mutate(p_boostrap_perm = if_else(cluster_log == TRUE, 0, 1))%>%
  ggplot(aes(timebins, t.y))+
  stat_summary(geom = 'line', size = 2)+
    geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax = 6.1 , fill = p.y),
            alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.8, label = "p uncorrected"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  
         # data = presidential,
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.4 , ymax =5.7 , fill = p_bonf),
             alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.4, label = "p Bonf"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.0 , ymax =5.3 , fill = p_holm),
             alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.0, label = "p Holm"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
    geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.6, ymax =4.9 , fill = p_boostrap_perm),
            alpha = 0.8)+
  geom_text(aes(x = 5, y = 4.6, label = "Clustering"),
                     size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+

  scale_fill_viridis_c()+
  theme_minimal()

plots_of$fullmodel_plot<- plots_of$fullmodel_plot +
 scale_x_continuous(limits = c(0,6), breaks = c(0,5))+ 
  # scale_fill_continuous(limits = c(0,5), breaks = c(0,5))+
    scale_fill_viridis_c(limits = c(1,1), breaks = c(0,1))+
  guides(fill = guide_colourbar(ticks = FALSE))
  


```

Plots    
```{r}
View(test.data_avgface)

test.data_avgface$cluster_counter<- if_else(test.data_avgface$cluster == TRUE,test.data_avgface$cluster_counter, NULL)
if_else(test.data_avgface$cluster_counter< 2, as.numeric(test.data_avgface$cluster_counter), as.numeric(test.data_avgface$cluster_counter-1))

test.data_avgface$p_bonf<- p.adjust(test.data_avgface$p, length(test.data_avgface$p), method = "bonferroni")
test.data_avgface$p_holm<- p.adjust(test.data_avgface$p, length(test.data_avgface$p), method = "holm")
  
 View( test.data_avgface) 
 
 
 test.data_avgface<-  test.data_avgface %>%
   mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))
 
plots_of$avg_global<- test.data_avgface%>%
     ggplot(aes(as.numeric(timebins), t))+
       geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9, ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf),
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  ggtitle("Global")+
  xlab("Time (s)")+
  ylab("t statistic")



plots_of$avg_global<- plots_of$avg_global+
  p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-6, 0, 6), limits = c(-6,6))

plots_of$avg_global
```


DO the same for ADFES and JEFFE
```{r}
db_of7_new_JEFFE<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE")
# create an empty dataframe that will hold the information from each test
test.data_avgface_jeffe<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )


# create a vector with the timebins
timebinout_avg_JEFFE<- unique(db_of7_new_JEFFE$timebin)

# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_JEFFE<- list()
# lmer


# i = 15 # currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore

i = 2


for (i in 1:length(timebinout_avg_JEFFE)) {
  testresults_avg_JEFFE<- lmer(log1p(face_action_AVG2 +.1) ~ VideoType_contrast + (1 |face_unique),
                      data = db_of7_new_JEFFE[db_of7_new_JEFFE$timebin == timebinout_avg_JEFFE[i],])
  
   summarytest_avg_JEFFE<- summary(testresults_avg_JEFFE)
   
   test.data_avgface_jeffe[i,1]<-timebinout_avg_JEFFE[i]
   test.data_avgface_jeffe[i,2]<- summarytest_avg_JEFFE[["coefficients"]][2,1]
   test.data_avgface_jeffe[i,3]<-summarytest_avg_JEFFE[["coefficients"]][2,4]
   test.data_avgface_jeffe[i,4]<-summarytest_avg_JEFFE[["coefficients"]][2,5]
   print(i)
   }

summary(testresults_avg_JEFFE)


# now sum adjancet timebins

test.data_avgface_jeffe$p_bonf<- p.adjust(test.data_avgface_jeffe$p, length(test.data_avgface_jeffe$p), method = "bonferroni")
test.data_avgface_jeffe$p_holm<- p.adjust(test.data_avgface_jeffe$p, length(test.data_avgface_jeffe$p), method = "holm")
  
 View( test.data_avgface_jeffe) 
 
 
 View(test.data_avgface_jeffe)
 
 
test.data_avgface_jeffe<- test.data_avgface_jeffe %>%
   mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))
 
 
plots_of$avg_JEFFE<- test.data_avgface_jeffe %>%
     ggplot(aes(as.numeric(timebins), t))+
  
    geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+

     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      # scale_fill_viridis_c()+
  # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  ggtitle("JEFFE")+
  xlab("Time (s)")+
  ylab("t statistic")

plots_of$avg_JEFFE<- plots_of$avg_JEFFE+ p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-6, 0, 6), limits = c(-6,6))
  
plots_of$avg_JEFFE
plots_of$avg_Sadness
plots_of$avg_global



  geom_text(aes(x = 5, y = 4.6, label = "Clustering"),
                     size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  

```

Boostrap JEFFE



```{r}
test.data_avgface_jeffe <- test.data_avgface_jeffe %>%
  mutate(cluster_log = if_else(test.data_avgface_jeffe$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
# View(test.data_avgface_jeffe)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
test.data_avgface_jeffe<- test.data_avgface_jeffe%>%
  mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
  mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
db_of7_new %>%
  filter(Dataset == 'JEFFE')%>%
  group_by(morph)%>%
  summarise(n = n()) # 1920
nrow(db_of7_new_JEFFE)
View(db_of7_new)


i = 1

View(testtemp)
db_of7_new%>%
  filter(Dataset == 'JEFFE')%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 48 vidoe per videotype
              


timebin_shuff_JEFFE<- unique(db_of7_new_JEFFE$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:100 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

# View(simulated_clusters_JEFFE)

timebin_random_JEFFE<- unique(db_of7_new_JEFFE$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE$cov<- as.character( simulated_clusters_JEFFE$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 # View(db_of7_new_JEFFE)
 
 db_of7_new_JEFFE$VideoType_contrast<- if_else(db_of7_new_JEFFE$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1
 for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  1920)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE  <- lmer(face_action_AVG2^2 ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE, db_of7_new_JEFFE$timebin == timebin_random_JEFFE[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE<- summary(lmer_bin_random_JEFFE)
            simulated_clusters_JEFFE[i,1]<- timebin_random_JEFFE[b] #save the exact value of time bin
            simulated_clusters_JEFFE[i,2]<- lmer_bin_random_summary_JEFFE[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE[i,3]<-lmer_bin_random_summary_JEFFE[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE[i,4]<-lmer_bin_random_summary_JEFFE[["coefficients"]][2,5] # p value
            simulated_clusters_JEFFE[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE[i,5] <-ifelse(length(lmer_bin_random_summary_JEFFE$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_JEFFE$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
 }
 
 # Now do clustering of shuffled data, and s
     View(simulated_clusters_JEFFE)
     table(simulated_clusters_JEFFE$cov == 'pass') # check how many convrgence errors we have
#       4489/(4489+35511)
     
     simulated_clusters_JEFFE%>%
       ggplot(aes(t))+
       geom_histogram()
     
     
      simulated_clusters%>%
       ggplot(aes(timebins, t))+
         # geom_smooth()
        stat_summary(geom = 'line')
     
       simulated_clusters_JEFFE%>%
       ggplot(aes(timebins, t))+
         # geom_smooth()
        stat_summary(geom = 'line')
         
     
# [1] 0.112225
    simulated_clusters_JEFFE$relgrad<- as.numeric(substr(simulated_clusters_JEFFE$cov,43, 48)) #extract the convergence tol
    simulated_clusters_JEFFE$relgrad_below<- if_else(simulated_clusters_JEFFE$relgrad< .02, TRUE, FALSE)
     table(simulated_clusters_JEFFE$relgrad_below)
     # 3/(61+3) ~ 4 %
     (63)/(4489+35511) #so the total non convergence rate is .001 *100 == 0.1%
     
    ### Cluster again on the shuffled data###
     
     # & simulated_clusters$timebins == nbins[b] do we need ti grouo it by timebine
     # for each simulation, cluster timebins
      sum_cluster_sim_JEFFE <- simulated_clusters_JEFFE %>% 
        # filter( simulated_clusters$sim == nsim[s])%>% # pick the current simulation
        arrange(sim, timebins)%>%
        group_by(sim)%>%
        mutate(cluster_shuffle_log = if_else(p < .05, TRUE, FALSE))%>% # create a logical highlighticng signiiant
        # bins
        mutate(Direction = if_else(t > 0 & cluster_shuffle_log == TRUE, "Positive", 
                                  if_else(t < 0 & cluster_shuffle_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # filter(!is.na(Direction))%>% 
        #significant because later we will need to group by this
      #group_by(cluster_shuffle_log,Direction)%>%
      # below we are creating a counter that that counts only the significant bins, separatelly by whether their are positive or
        #negative to cinfirm if it works 
        group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_countershuffle  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(sim, cluster_countershuffle)%>%
      mutate(t_sum_shuffle_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_shuffle_dir = if_else(cluster_shuffle_log == TRUE, t_sum_shuffle_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE),
                                      cluster_countershuffle, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE), 
                                      t_sum_shuffle_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))%>%
        
        #fill it
      fill(MaxCLust_label, .direction = "updown")%>%
      fill(MaxCLust_value, .direction = "updown")%>%
      fill(MaxCLust_direction, .direction = "updown")
      
      View(sum_cluster_sim_JEFFE)
      # test sim 4 that had a probpem
      # sim4<- subset(sum_cluster_sim, sum_cluster_sim$sim == 4)
      # View(sim4)
    unique(sum_cluster_sim_JEFFE$MaxCLust_value) 
    
     # a few warnings - invalid factor NA levels = 
 # ma NA = because there is no max that survived sigificance
    View(sum_cluster_sim_JEFFE)
    
    
    sum_cluster_sim_JEFFE%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, t))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
sum_cluster_sim_JEFFE%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, NULL))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
    
View(test.data_avgface_jeffe)

test.data_avgface_jeffe%>%
  # mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, t))%>%
  ggplot(aes(timebins, t))+
  stat_summary(geom = 'line')



# calculation of propabilities
# p-value for the cluster
# p value is calculated by taking the number of times the sum t statistic was greater than the observed one


simulattion_vs_data_JEFFE<- left_join(sum_cluster_sim_JEFFE, test.data_avgface_jeffe, by = 'timebins' )
View(simulattion_vs_data_JEFFE)


simulattion_vs_data_JEFFE<- simulattion_vs_data_JEFFE%>%
    ungroup()%>%
      # group_by(sim,Direction.y) %>%
  fill(MaxCLust_value.y, .direction = "down")%>%
  fill(MaxCLust_direction.y, .direction = "down")%>%
  # fill(MaxCLust_value.y, .direction = "down")%>%
  mutate(MAX_clust_count= if_else(is.na(MaxCLust_value.x) == TRUE,0, 
                                  if_else(abs(!is.na(MaxCLust_value.x))> abs(!is.na(MaxCLust_value.y)), 1, 0)))


# I think we need to take the clusters to columns (SPREAD)
# How many clusters did we have in the data
unique(simulattion_vs_data_JEFFE$cluster_counter)
simulattion_vs_data_JEFFE  <- simulattion_vs_data_JEFFE %>%
  # group_by(cluster_counter)%>%
  mutate(cluster1_tsum = if_else(cluster_counter == 1, t_sum_dir, NULL))%>%
  mutate(cluster1_direction = if_else(cluster_counter == 1, MaxCLust_direction.y, NULL))%>%
  mutate(cluster2_tsum = if_else(cluster_counter == 2, t_sum_dir, NULL))%>%
  mutate(cluster2_direction = if_else(cluster_counter == 2, MaxCLust_direction.y, NULL))%>%
  mutate(cluster3_tsum = if_else(cluster_counter == 3, t_sum_dir, NULL))%>%
  mutate(cluster3_direction = if_else(cluster_counter == 3,MaxCLust_direction.y, NULL))%>%
  fill(cluster1_tsum, .direction = 'updown')%>%
  fill(cluster2_tsum, .direction = 'updown')%>%
  fill(cluster3_tsum, .direction = 'updown')%>%
  fill(cluster1_direction , .direction = 'updown')%>%
  fill(cluster2_direction , .direction = 'updown')%>%
  fill(cluster3_direction , .direction = 'updown')

View(simulattion_vs_data_JEFFE)


unique(simulattion_vs_data$MAX_clust_count)
View(simulattion_vs_data_JEFFE)
#  i think we need to tae the t value when the simulations are not significant
table(is.na(simulattion_vs_data_JEFFE$t_sum_shuffle_dir))
 simulattion_vs_data_JEFFE <-  simulattion_vs_data_JEFFE %>%
   
  mutate(Max_clust_value_and_ns_t = if_else(is.na(t_sum_shuffle_dir), t.x, t_sum_shuffle_dir))%>%
  mutate(Max_clust_value_and_ns_t_jelka = t_sum_shuffle_dir)%>%
  mutate(Clust1_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster2_tsum), 1,0))%>%
  mutate(Clust3_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster3_tsum), 1,0))%>%
   
  mutate(Clust1_sim_biggerthan_data1 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data2 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster2_tsum), 1,0))%>%
  mutate(Clust3_sim_biggerthan_data3 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster3_tsum), 1,0))%>%

  # mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t) > abs(cluster2_tsum), 1,0))%>%
  mutate(clust1_p =  sum(Clust1_sim_biggerthan_data)/n())%>%
  mutate(clust2_p =  sum(Clust2_sim_biggerthan_data)/n())%>%
  mutate(clust3_p =  sum(Clust3_sim_biggerthan_data)/n())%>%
   
  mutate(clust1_p_jelka =  sum(Clust1_sim_biggerthan_data)/2001)%>%
  mutate(clust2_p_jelka =  sum(Clust2_sim_biggerthan_data)/2001)%>%
  mutate(clust3_p_jelka =  sum(Clust3_sim_biggerthan_data)/2001)
 # get p values
p_values_JEFFE<- 
  simulattion_vs_data_JEFFE %>%
  # subset(simulattion_vs_data_JEFFE, is.na(as.factor(simulattion_vs_data_JEFFE$cluster_counter)))%%
  group_by(cluster_counter)%>%
  summarise_at(c('clust1_p', 'clust2_p', 'clust3_p', 'clust1_p_jelka', 'clust2_p_jelka', 'clust3_p_jelka'), mean, na.rm = TRUE)

p_values_JEFFE
test.data_avgface_jeffe<-left_join(test.data_avgface_jeffe, p_values_JEFFE)

View(test.data_avgface_jeffe)

plots_of$JEFFE_full<- test.data_avgface_jeffe$%>%
  mutate(p_clustering =  if_else(is.na(cluster_counter),1,
                                 if_else(cluster_counter == 1, clust1_p,
                                         if_else(cluster_counter == 2, clust2_p,
                                                 if_else(cluster_counter == 3, clust3_p,
                                                         NULL)))))%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax =6 , fill = p),
            alpha = 0.8)+
  geom_text(aes(x = 5, y = 5.8, label = "p uncorrected",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+

  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.4 , ymax =5.7 , fill = p_holm),
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 5.4, label = "p Holm",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5, ymax =5.3 , fill = p_bonf), 
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 5, label = "p Bonf",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.6, ymax =4.9 , fill = p_clustering), 
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 4.6, label = "Clustering",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
     geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'red')+
  geom_hline(yintercept = 1.96, linetype = 'dashed', size = 1, colour = 'red')+
   geom_hline(yintercept = -1.96, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE")

plots_of$JEFFE_full<- plots_of$JEFFE_full+
  p$paper +
   scale_x_continuous(limits = c(0,6), breaks = c(0,5))+ 
  # scale_fill_continuous(limits = c(0,5), breaks = c(0,5))+
    scale_fill_viridis_c(limits = c(0,.1), breaks = c(0,1))+
  guides(fill = guide_colourbar(ticks = FALSE))

plots_of$JEFFE_full  


test.data_avgface_jeffe%>%
  ggplot(aes(timebins,t))+
  geom_line()+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax =6 , fill = p))
```
    

```{r}
simulattion_vs_data%>%
  mutate(p_boostrap_perm = if_else(cluster_log == TRUE, 0, 1))%>%
  ggplot(aes(timebins, t.y))+
  stat_summary(geom = 'line')+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.6 , ymax =4.9 , fill = p_boostrap_perm),
            alpha = 0.8)+
  geom_text(aes(x = 5, y = 4.6, label = "CBP"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax =6.1 , fill = p_bonf),
             alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.8, label = "Bonf"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.4 , ymax =5.7 , fill = p_holm),
             alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.4, label = "Holm"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.0 , ymax = 5.3 , fill = p.y),
            alpha = 0.8)+
    geom_text(aes(x = 5, y = 5.0, label = "p"),
         # data = presidential,
         size = 3, vjust = 0, hjust = 0, check_overlap = TRUE)+
  scale_fill_viridis_c()+
  theme_minimal()



```


ADFES - AVG face

```{r}

db_of7_new_ADFES<- subset(db_of7_new, db_of7_new$Dataset == "ADFES")
# create an empty dataframe that will hold the information from each test
test.data_avgface_ADFES<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )


# create a vector with the timebins
timebinout_avg_ADFES<- unique(db_of7_new_ADFES$timestamp)

# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_ADFES<- list()
# lmer


i = 15 # currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore

i = 1


for (i in 1:length(timebinout_avg_ADFES)) {
  testresults_avg_ADFES<- lmer(face_action_AVG2* ~ VideoType_contrast + (1 |face_unique),
                      data = db_of7_new_ADFES[db_of7_new_ADFES$timestamp == timebinout_avg_ADFES[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of8 [db_of8$timebin == timebinout[i] & db_of8$Dataset !="ADFES",])
   summarytest_avg_ADFES<- summary(testresults_avg_ADFES)
   
   test.data_avgface_ADFES[i,1]<-timebinout_avg_ADFES[i]
  test.data_avgface_ADFES[i,2]<- summarytest_avg_ADFES[["coefficients"]][2,1]
   test.data_avgface_ADFES[i,3]<-summarytest_avg_ADFES[["coefficients"]][2,4]
   test.data_avgface_ADFES[i,4]<-summarytest_avg_ADFES[["coefficients"]][2,5]
   # test.data[i,5]<- testresults@optinfo$val
   print(i)
   }

summary(testresults_avg_ADFES)


# now sum adjancet timebins

test.data_avgface_ADFES$p_bonf<- p.adjust(test.data_avgface_ADFES$p, length(test.data_avgface_ADFES$p), method = "bonferroni")
test.data_avgface_ADFES$p_holm<- p.adjust(test.data_avgface_ADFES$p, length(test.data_avgface_ADFES$p), method = "holm")
  
 View( test.data_avgface_ADFES) 
 
 test.data_avgface_ADFES<- test.data_avgface_ADFES %>%
   mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))
 
 
plots_of$avg_ADFES <- test.data_avgface_ADFES %>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax =6 , fill = p),
            alpha = 0.8)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+

     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      # scale_fill_viridis_c()+
  # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  ggtitle("ADFES")+
  xlab("Time (s)")+
  ylab("t statistic")

plots_of$avg_ADFES
plots_of$avg_ADFES<- plots_of$avg_ADFES+ p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-2, 2, 6), limits = c(-3,6))

plots_of$avg_ADFES<- plots_of$avg_ADFES+ p$paper+
   scale_x_continuous(limits = c(0,6), breaks = c(0,5))+ 
  # scale_fill_continuous(limits = c(0,5), breaks = c(0,5))+
    scale_fill_viridis_c(limits = c(0,1), breaks = c(0,1))+
  guides(fill = guide_colourbar(ticks = FALSE))
plots_of$avg_global

plots_of$avg_ADFES




```


Boostrap ADFES



```{r}

test.data_avgface_ADFES <- test.data_avgface_ADFES %>%
  mutate(cluster_log = if_else(test.data_avgface_ADFES$p< .1, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_avgface_ADFES)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_avgface_ADFES<- test.data_avgface_ADFES%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
db_of7_new %>%
  filter(Dataset == 'ADFES')%>%
  group_by(morph)%>%
  summarise(n = n()) # 1920

View(db_of7_new)

i = 1

View(testtemp)

db_of7_new%>%
  filter(Dataset == 'ADFES')%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 48 vidoe per videotype
              

timebin_shuff_ADFES<- unique(db_of7_new_ADFES$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_ADFES<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_ADFES)

timebin_random_ADFES<- unique(db_of7_new_ADFES$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_ADFES$cov<- as.character( simulated_clusters_ADFES$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_ADFES)
 
 db_of7_new_ADFES$VideoType_contrast<- if_else(db_of7_new_ADFES$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_ADFES$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  1920)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_ADFES  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_ADFES, db_of7_new_ADFES$timebin == timebin_random_ADFES[b]))

        #store results from the somularion
            lmer_bin_random_summary_ADFES<- summary(lmer_bin_random_ADFES)
            simulated_clusters_ADFES[i,1]<- timebin_random_ADFES[b] #save the exact value of time bin
            simulated_clusters_ADFES[i,2]<- lmer_bin_random_summary_ADFES[["coefficients"]][2,1] # s
            simulated_clusters_ADFES[i,3]<-lmer_bin_random_summary_ADFES[["coefficients"]][2,4] # t statistic
            simulated_clusters_ADFES[i,4]<-lmer_bin_random_summary_ADFES[["coefficients"]][2,5] # p value
            simulated_clusters_ADFES[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_ADFES[i,5] <-ifelse(length(lmer_bin_random_summary_ADFES$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_ADFES$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}



```

ADFES boostrap clustering

```{r}

 # Now do clustering of shuffled data, and s
     View(simulated_clusters_ADFES)
     table(simulated_clusters_ADFES$cov == 'pass') # check how many convrgence errors we have
#       4489/(4489+35511)
     
     simulated_clusters_ADFES%>%
       ggplot(aes(t))+
       geom_histogram()
     

      simulated_clusters_ADFES%>%
       ggplot(aes(timebins, t))+
         geom_line(aes(group = sim))+
        stat_summary(geom = 'line')

         
# [1] 0.112225
    simulated_clusters_ADFES$relgrad<- as.numeric(substr(simulated_clusters_ADFES$cov,43, 48)) #extract the convergence tol
    simulated_clusters_ADFES$relgrad_below<- if_else(simulated_clusters_ADFES$relgrad< .02, TRUE, FALSE)
     table(simulated_clusters_ADFES$relgrad_below)
     # 3/(61+3) ~ 4 %
     # (63)/(4489+35511) #so the total non convergence rate is .001 *100 == 0.1%
     
    ### Cluster again on the shuffled data###
     
     # & simulated_clusters$timebins == nbins[b] do we need ti grouo it by timebine
     # for each simulation, cluster timebins
      sum_cluster_sim_ADFES <- simulated_clusters_ADFES %>% 
        # filter( simulated_clusters$sim == nsim[s])%>% # pick the current simulation
        arrange(sim, timebins)%>%
        group_by(sim)%>%
        mutate(cluster_shuffle_log = if_else(p < .05, TRUE, FALSE))%>% # create a logical highlighticng signiiant
        # bins
        mutate(Direction = if_else(t > 0 & cluster_shuffle_log == TRUE, "Positive", 
                                  if_else(t < 0 & cluster_shuffle_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # filter(!is.na(Direction))%>% 
        #significant because later we will need to group by this
      #group_by(cluster_shuffle_log,Direction)%>%
      # below we are creating a counter that that counts only the significant bins, separatelly by whether their are positive or
        #negative to cinfirm if it works 
        group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_countershuffle  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(sim, cluster_countershuffle)%>%
      mutate(t_sum_shuffle_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_shuffle_dir = if_else(cluster_shuffle_log == TRUE, t_sum_shuffle_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE),
                                      cluster_countershuffle, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE), 
                                      t_sum_shuffle_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))%>%
        
        #fill it
      fill(MaxCLust_label, .direction = "updown")%>%
      fill(MaxCLust_value, .direction = "updown")%>%
      fill(MaxCLust_direction, .direction = "updown")
      
      View(sum_cluster_sim_ADFES)
      # test sim 4 that had a probpem
      # sim4<- subset(sum_cluster_sim, sum_cluster_sim$sim == 4)
      # View(sim4)
    unique(sum_cluster_sim_ADFES$MaxCLust_value) 
    
     # a few warnings - invalid factor NA levels = 
 # ma NA = because there is no max that survived sigificance

    
    sum_cluster_sim_ADFES%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, t))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
sum_cluster_sim_ADFES%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, NULL))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
    
View(sum_cluster_sim_ADFES)

```

computing pvalues for ADFES boostrap

```{r}
# calculation of propabilities
# p-value for the cluster
# p value is calculated by taking the number of times the sum t statistic was greater than the observed one

View(sum_cluster_sim_ADFES)
View( test.data_avgface_ADFES)
sum_cluster_sim_ADFES$timebins1<- substr((sum_cluster_sim_ADFES$timebins+.06),1,3)
test.data_avgface_ADFES$timebins1<-substr( test.data_avgface_ADFES$timebins,1,3)

simulattion_vs_data_ADFES<- left_join(sum_cluster_sim_ADFES, test.data_avgface_ADFES, by =
                                        c('timebins1'))
View(simulattion_vs_data_ADFES)


simulattion_vs_data_ADFES<- simulattion_vs_data_ADFES%>%
    ungroup()%>%
      # group_by(sim,Direction.y) %>%
  fill(MaxCLust_value.y, .direction = "down")%>%
  fill(MaxCLust_direction.y, .direction = "down")%>%
  # fill(MaxCLust_value.y, .direction = "down")%>%
  mutate(MAX_clust_count= if_else(is.na(MaxCLust_value.x) == TRUE,0, 
                                  if_else(abs(!is.na(MaxCLust_value.x))> abs(!is.na(MaxCLust_value.y)), 1, 0)))


# I think we need to take the clusters to columns (SPREAD)
# How many clusters did we have in the data
unique(simulattion_vs_data_ADFES$cluster_counter)
simulattion_vs_data_ADFES  <- simulattion_vs_data_ADFES %>%
  # group_by(cluster_counter)%>%
  mutate(cluster1_tsum = if_else(cluster_counter == 1, t_sum_dir, NULL))%>%
  mutate(cluster1_direction = if_else(cluster_counter == 1, MaxCLust_direction.y, NULL))%>%
  mutate(cluster2_tsum = if_else(cluster_counter == 2, t_sum_dir, NULL))%>%
  mutate(cluster2_direction = if_else(cluster_counter == 2, MaxCLust_direction.y, NULL))%>%
  mutate(cluster3_tsum = if_else(cluster_counter == 3, t_sum_dir, NULL))%>%
  mutate(cluster3_direction = if_else(cluster_counter == 3,MaxCLust_direction.y, NULL))%>%
  fill(cluster1_tsum, .direction = 'updown')%>%
  fill(cluster2_tsum, .direction = 'updown')%>%
  fill(cluster3_tsum, .direction = 'updown')%>%
  fill(cluster1_direction , .direction = 'updown')%>%
  fill(cluster2_direction , .direction = 'updown')%>%
  fill(cluster3_direction , .direction = 'updown')

View(simulattion_vs_data_ADFES)


unique(simulattion_vs_data$MAX_clust_count)
View(simulattion_vs_data_ADFES)
#  i think we need to tae the t value when the simulations are not significant
table(is.na(simulattion_vs_data_ADFES$t_sum_shuffle_dir))
 simulattion_vs_data_ADFES <-  simulattion_vs_data_ADFES %>%
   
  mutate(Max_clust_value_and_ns_t = if_else(is.na(t_sum_shuffle_dir), t.x, t_sum_shuffle_dir))%>%
  mutate(Max_clust_value_and_ns_t_jelka = t_sum_shuffle_dir)%>%
  mutate(Clust1_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster2_tsum), 1,0))%>%
  # mutate(Clust3_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster3_tsum), 1,0))%>%
   
  mutate(Clust1_sim_biggerthan_data1 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data2 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster2_tsum), 1,0))%>%
  # mutate(Clust3_sim_biggerthan_data3 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster3_tsum), 1,0))%>%

  # mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t) > abs(cluster2_tsum), 1,0))%>%
  mutate(clust1_p =  sum(Clust1_sim_biggerthan_data)/n())%>%
  mutate(clust2_p =  sum(Clust2_sim_biggerthan_data)/n())%>%
  # mutate(clust3_p =  sum(Clust3_sim_biggerthan_data)/n())%>%
   
  mutate(clust1_p_jelka =  sum(Clust1_sim_biggerthan_data)/2001)%>%
  mutate(clust2_p_jelka =  sum(Clust2_sim_biggerthan_data)/2001)
  # mutate(clust3_p_jelka =  sum(Clust3_sim_biggerthan_data)/2001)
 # get p values
p_values_ADFES<- 
  simulattion_vs_data_ADFES %>%
  # subset(simulattion_vs_data_ADFES, is.na(as.factor(simulattion_vs_data_ADFES$cluster_counter)))%%
  group_by(cluster_counter)%>%
  summarise_at(c('clust1_p', 'clust2_p', 'clust3_p', 'clust1_p_jelka', 'clust2_p_jelka', 'clust3_p_jelka'), mean, na.rm = TRUE)

p_values_ADFES
test.data_avgface_ADFES<-left_join(test.data_avgface_ADFES, p_values_ADFES)

View(test.data_avgface_ADFES)
test.data_avgface_ADFES<- test.data_avgface_ADFES%>%
  mutate(p_clustering =  if_else(is.na(cluster_counter),1,
                                 if_else(cluster_counter == 1, clust1_p,
                                         if_else(cluster_counter == 2, clust2_p,
                                                 # if_else(cluster_counter == 3, clust3_p,
                                                         NULL))))
plots_of$ADFES_bbostrap<- test.data_avgface_ADFES%>%  
ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.8 , ymax =6 , fill = p),
            alpha = 0.8)+
  geom_text(aes(x = 5, y = 5.8, label = "p uncorrectected",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+

  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.4 , ymax =5.7 , fill = p_holm),
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 5.4, label = "p Holm",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5, ymax =5.3 , fill = p_bonf), 
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 5, label = "p Bonf",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.6, ymax =4.9 , fill = p_clustering), 
            alpha = 0.8)+
     geom_text(aes(x = 5, y = 4.6, label = "p Cluster",
                size = 3, vjust = 0, hjust = 0, check_overlap = TRUE))+
     geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'red')+
  geom_hline(yintercept = 1.96, linetype = 'dashed', size = 1, colour = 'red')+
   geom_hline(yintercept = -1.96, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES - Average Face action ~ Morph")

plots_of$ADFES_bbostrap

```


By emotion now
Anger

```{r}

# db_of7_new$Emotion
db_of7_new_avg_Anger<- subset(db_of7_new, db_of7_new$Emotion == "Anger")



test.data_by_avg_Anger<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Anger<- unique(db_of7_new_avg_Anger$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Anger<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 1
for (i in 1:length(timestamp_avg_Anger)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Anger_results<- lmer(log1p(D1+.1) ~ VideoType_contrast + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Anger[db_of7_new_avg_Anger$timebin == timebin_avg_Anger[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Anger_results_sum<- summary(avg_Anger_results)

   test.data_by_avg_Anger[i,1]<-timestamp_avg_Anger[i]
   test.data_by_avg_Anger[i,2]<- avg_Anger_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Anger[i,3]<- avg_Anger_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Anger[i,4]<- avg_Anger_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Anger_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Anger$p_holm<- p.adjust(test.data_by_avg_Anger$p, length(test.data_by_avg_Anger$p), method = "holm")
 
 test.data_by_avg_Anger$p_bonf<- p.adjust(test.data_by_avg_Anger$p, length(test.data_by_avg_Anger$p), 
                                          method ="bonf")
  View(test.data_by_avg_Anger)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
  
  
  
    test.data_by_avg_Anger$cluster_counter
    
    View(test.data_by_avg_Anger)
  test.data_by_avg_Anger<-   test.data_by_avg_Anger %>%
  mutate(p_clustering =  if_else(is.na(cluster_counter),1,
                                 if_else(cluster_counter == 1, clust1_p,
                                         if_else(cluster_counter == 2, clust2_p,
                                                 # if_else(cluster_counter == 3, clust3_p,
                                                         NULL))))

  
  View(   test.data_by_avg_Anger)
  
test.data_by_avg_Anger<- test.data_by_avg_Anger %>%
  mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))
  

plots_of$avg_Anger <- 
   test.data_by_avg_Anger %>%
  ggplot(aes(as.numeric(timebins), t))+
    geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+

  geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
  stat_summary(geom = 'line', size = 2)+
               theme_classic()+
   geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  # scale_colour_gradient2(limits = c(0,1))+
  # ggtitle("AVG face motion ~ Morph - Anger")+
  ggtitle("Anger")+
  xlab("Time (s)")+
ylab("t statistic")
   
plots_of$avg_Anger<- plots_of$avg_Anger+p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-2, 2, 6), limits = c(-2,6))

plots_of$avg_Anger

# sf
  p$graphstyle <-  theme(#base plot theme
  # axis.line.y = element_blank(),
  # axis.line.x = element_blank(),
  strip.text.x = element_text(size = 11*(sf+.5),  colour = "black"),
  strip.text.y = element_text(size = 11*(sf+.5),  colour = "black"),
  panel.border = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  
  # plot title
  plot.title = element_text(size = 14*(sf+3),  colour = "black"),
  #panel.background = element_rect(fill="transparent"),
  #panel.border = element_rect(fill="transparent"),
  
  # LEGEND
  #legend.position = "top", 
  #legend.direction = "horizontal",
  #legend.key.size = unit(.5, "cm"),
  #legend.text = element_text(size = 10*sf+.3),
  legend.title = element_text(size = 10*(sf+1)),
  #legend.key.size = unit(.5, "cm"),
  legend.text = element_text(size = 10*(sf+.5)),
  #legend.title=element_blank(),
  #legend.text = element_blank(),
  text=element_text(size = 16, family = "sans"),
  axis.text.x = element_text(size = 14*(sf+1.5), family = "sans", colour = "black"),
  axis.text.y = element_text(size = 14*(sf+1.5), family = "sans", colour = "black"),
  #axis.ticks = element_blank(),
  # strip shades (reco rectagles)
  strip.background = element_blank(),
  #axis.text.y = element_text(size= 18, family = "Arial Narrow", colour="black"),
  axis.title.y=element_text(size = 16*(sf+1.5), margin=margin(0,5,0,0)),
  axis.title.x=element_text(size = 16*(sf+1.5), margin=margin(0,5,0,0)),
  legend.key = element_rect(colour = "transparent", fill="transparent"))


```

Anger boostrapping

```{r}
View(test.data_by_avg_Anger)

test.data_by_avg_Anger <- test.data_by_avg_Anger %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Anger$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Anger)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Anger<- test.data_by_avg_Anger%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Anger)
db_of7_new_avg_Anger%>%
  # filter( Emotion == "Anger")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Anger%>%
  # filter(Emotion == "Anger")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Anger<- unique(db_of7_new_avg_Anger$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Anger<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Anger)

# timebin_random_ADFES<- unique(db_of7_new_avg_Anger$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Anger$cov<- as.character( simulated_clusters_Anger$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Anger)
 
 db_of7_new_avg_Anger$VideoType_contrast<- if_else(db_of7_new_avg_Anger$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Anger$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Anger  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Anger, db_of7_new_avg_Anger$timebin == timebin_shuff_Anger[b]))

        #store results from the somularion
            lmer_bin_random_summary_Anger<- summary(lmer_bin_random_Anger)
            simulated_clusters_Anger[i,1]<- timebin_shuff_Anger[b] #save the exact value of time bin
            simulated_clusters_Anger[i,2]<- lmer_bin_random_summary_Anger[["coefficients"]][2,1] # s
            simulated_clusters_Anger[i,3]<-lmer_bin_random_summary_Anger[["coefficients"]][2,4] # t statistic
            simulated_clusters_Anger[i,4]<-lmer_bin_random_summary_Anger[["coefficients"]][2,5] # p value
            simulated_clusters_Anger[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Anger[i,5] <-ifelse(length(lmer_bin_random_summary_Anger$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Anger$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}



```

<!-- ADFES boostrap clustering -->

```{r}

 # Now do clustering of shuffled data, and s
     View(simulated_clusters_ADFES)
     table(simulated_clusters_ADFES$cov == 'pass') # check how many convrgence errors we have
#       4489/(4489+35511)
     
     simulated_clusters_ADFES%>%
       ggplot(aes(t))+
       geom_histogram()
     

      simulated_clusters_ADFES%>%
       ggplot(aes(timebins, t))+
         geom_line(aes(group = sim))+
        stat_summary(geom = 'line')

         
# [1] 0.112225
    simulated_clusters_ADFES$relgrad<- as.numeric(substr(simulated_clusters_ADFES$cov,43, 48)) #extract the convergence tol
    simulated_clusters_ADFES$relgrad_below<- if_else(simulated_clusters_ADFES$relgrad< .02, TRUE, FALSE)
     table(simulated_clusters_ADFES$relgrad_below)
     # 3/(61+3) ~ 4 %
     # (63)/(4489+35511) #so the total non convergence rate is .001 *100 == 0.1%
     
    ### Cluster again on the shuffled data###
     
     # & simulated_clusters$timebins == nbins[b] do we need ti grouo it by timebine
     # for each simulation, cluster timebins
      sum_cluster_sim_ADFES <- simulated_clusters_ADFES %>% 
        # filter( simulated_clusters$sim == nsim[s])%>% # pick the current simulation
        arrange(sim, timebins)%>%
        group_by(sim)%>%
        mutate(cluster_shuffle_log = if_else(p < .05, TRUE, FALSE))%>% # create a logical highlighticng signiiant
        # bins
        mutate(Direction = if_else(t > 0 & cluster_shuffle_log == TRUE, "Positive", 
                                  if_else(t < 0 & cluster_shuffle_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # filter(!is.na(Direction))%>% 
        #significant because later we will need to group by this
      #group_by(cluster_shuffle_log,Direction)%>%
      # below we are creating a counter that that counts only the significant bins, separatelly by whether their are positive or
        #negative to cinfirm if it works 
        group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_countershuffle  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(sim, cluster_countershuffle)%>%
      mutate(t_sum_shuffle_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_shuffle_dir = if_else(cluster_shuffle_log == TRUE, t_sum_shuffle_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE),
                                      cluster_countershuffle, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_shuffle_dir) == max(abs(t_sum_shuffle_dir), na.rm = TRUE), 
                                      t_sum_shuffle_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))%>%
        
        #fill it
      fill(MaxCLust_label, .direction = "updown")%>%
      fill(MaxCLust_value, .direction = "updown")%>%
      fill(MaxCLust_direction, .direction = "updown")
      
      View(sum_cluster_sim_ADFES)
      # test sim 4 that had a probpem
      # sim4<- subset(sum_cluster_sim, sum_cluster_sim$sim == 4)
      # View(sim4)
    unique(sum_cluster_sim_ADFES$MaxCLust_value) 
    
     # a few warnings - invalid factor NA levels = 
 # ma NA = because there is no max that survived sigificance

    
    sum_cluster_sim_ADFES%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, t))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
sum_cluster_sim_ADFES%>%
  mutate(MaxCLust_value = if_else(cluster_shuffle_log == TRUE, MaxCLust_value, NULL))%>%
  ggplot(aes(MaxCLust_value))+
  geom_histogram()
    
View(sum_cluster_sim_ADFES)




```




Joyy - Global average face
```{r}
db_of7_new_avg_Joy<- subset(db_of7_new, db_of7_new$Emotion == "Joy")

factor(db_of7_new_avg_Joy$morph)

test.data_by_avg_Joy<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Joy<- unique(db_of7_new_avg_Joy$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Joy<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_avg_Joy)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Joy_results<- lmer(log1p(D1+.1) ~ VideoType_contrast + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Joy[db_of7_new_avg_Joy$timebin == timebin_avg_Joy[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Joy_results_sum<- summary(avg_Joy_results)

   test.data_by_avg_Joy[i,1]<-timestamp_avg_Joy[i]
   test.data_by_avg_Joy[i,2]<- avg_Joy_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Joy[i,3]<- avg_Joy_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Joy[i,4]<- avg_Joy_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Joy_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Joy$p_holm<- p.adjust(test.data_by_avg_Joy$p, length(test.data_by_avg_Joy$p), method = "holm")
 
 test.data_by_avg_Joy$p_bonf<- p.adjust(test.data_by_avg_Joy$p, length(test.data_by_avg_Joy$p), 
                                          method ="bonf")
  View(test.data_by_avg_Joy)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
  
  
  
test.data_by_avg_Joy<- test.data_by_avg_Joy %>%
  mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))
    

plots_of$avg_Joy <- 
   test.data_by_avg_Joy%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  
   geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     # ylim(1,6)+
   scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
      # scale_fill_viridis_c()+
     # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("Happiness")+
  xlab("Time (s)")+
  ylab("t statistic")
   
plots_of$avg_Joy

plots_of$avg_Joy<- plots_of$avg_Joy+p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-2, 2, 6), limits = c(-2,6))
  # theme(
    # axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank())

plots_of$avg_Joy




```

Joy Global - boostrap

```{r}
View(test.data_by_avg_Joy)

test.data_by_avg_Joy <- test.data_by_avg_Joy %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Joy$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Joy)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Joy<- test.data_by_avg_Joy%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Joy)
db_of7_new_avg_Joy%>%
  # filter( Emotion == "Joy")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Joy%>%
  # filter(Emotion == "Joy")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Joy<- unique(db_of7_new_avg_Joy$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Joy<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Joy)

# timebin_random_ADFES<- unique(db_of7_new_avg_Joy$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Joy$cov<- as.character( simulated_clusters_Joy$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Joy)
 
 db_of7_new_avg_Joy$VideoType_contrast<- if_else(db_of7_new_avg_Joy$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Joy$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Joy  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Joy, db_of7_new_avg_Joy$timebin == timebin_shuff_Joy[b]))

        #store results from the somularion
            lmer_bin_random_summary_Joy<- summary(lmer_bin_random_Joy)
            simulated_clusters_Joy[i,1]<- timebin_shuff_Joy[b] #save the exact value of time bin
            simulated_clusters_Joy[i,2]<- lmer_bin_random_summary_Joy[["coefficients"]][2,1] # s
            simulated_clusters_Joy[i,3]<-lmer_bin_random_summary_Joy[["coefficients"]][2,4] # t statistic
            simulated_clusters_Joy[i,4]<-lmer_bin_random_summary_Joy[["coefficients"]][2,5] # p value
            simulated_clusters_Joy[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Joy[i,5] <-ifelse(length(lmer_bin_random_summary_Joy$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Joy$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}




```



Fear
```{r}
# db_of7_new$Emotion
db_of7_new_avg_Fear<- subset(db_of7_new, db_of7_new$Emotion == "Fear")



test.data_by_avg_Fear<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Fear<- unique(db_of7_new_avg_Fear$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Fear<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 1
for (i in 1:length(timestamp_avg_Fear)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Fear_results<- lmer(log1p(D1+.1) ~ VideoType_contrast + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Fear[db_of7_new_avg_Fear$timebin == timebin_avg_Fear[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Fear_results_sum<- summary(avg_Fear_results)

   test.data_by_avg_Fear[i,1]<-timebin_avg_Fear[i]
   test.data_by_avg_Fear[i,2]<- avg_Fear_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Fear[i,3]<- avg_Fear_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Fear[i,4]<- avg_Fear_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Fear_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Fear$p_holm<- p.adjust(test.data_by_avg_Fear$p, length(test.data_by_avg_Fear$p), method = "holm")
 
 test.data_by_avg_Fear$p_bonf<- p.adjust(test.data_by_avg_Fear$p, length(test.data_by_avg_Fear$p), 
                                          method ="bonf")
  View(test.data_by_avg_Fear)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
  
  View(test.data_by_avg_Fear)
  
test.data_by_avg_Fear<- test.data_by_avg_Fear %>%
  mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))

plots_of$avg_Fear <- 
   test.data_by_avg_Fear %>%
     ggplot(aes(as.numeric(timebins), t))+
  geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+
   
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  
   geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
      # scale_fill_viridis_c()+
     # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("Fear")+
  xlab("Time (s)")+
  ylab("t statistic")
   
plots_of$avg_Fear 

plots_of$avg_Fear <- plots_of$avg_Fear +p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-2, 2, 6), limits = c(-2,6))

   
plots_of$avg_Fear



```

Fear Boostrap Global
```{r}
View(test.data_by_avg_Fear)

test.data_by_avg_Fear <- test.data_by_avg_Fear %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Fear$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Fear)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Fear<- test.data_by_avg_Fear%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Fear)
db_of7_new_avg_Fear%>%
  # filter( Emotion == "Fear")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Fear%>%
  # filter(Emotion == "Fear")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Fear<- unique(db_of7_new_avg_Fear$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Fear<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Fear)

# timebin_random_ADFES<- unique(db_of7_new_avg_Fear$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Fear$cov<- as.character( simulated_clusters_Fear$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Fear)
 
 db_of7_new_avg_Fear$VideoType_contrast<- if_else(db_of7_new_avg_Fear$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Fear$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Fear  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Fear, db_of7_new_avg_Fear$timebin == timebin_shuff_Fear[b]))

        #store results from the somularion
            lmer_bin_random_summary_Fear<- summary(lmer_bin_random_Fear)
            simulated_clusters_Fear[i,1]<- timebin_shuff_Fear[b] #save the exact value of time bin
            simulated_clusters_Fear[i,2]<- lmer_bin_random_summary_Fear[["coefficients"]][2,1] # s
            simulated_clusters_Fear[i,3]<-lmer_bin_random_summary_Fear[["coefficients"]][2,4] # t statistic
            simulated_clusters_Fear[i,4]<-lmer_bin_random_summary_Fear[["coefficients"]][2,5] # p value
            simulated_clusters_Fear[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Fear[i,5] <-ifelse(length(lmer_bin_random_summary_Fear$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Fear$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}



 
# calculation of propabilities
# p-value for the cluster
# p value is calculated by taking the number of times the sum t statistic was greater than the observed one

# View(sum_cluster_sim_ADFES)
# View( test.data_avgface_ADFES)
# sum_cluster_sim_ADFES$timebins1<- substr((sum_cluster_sim_ADFES$timebins+.06),1,3)
# test.data_avgface_ADFES$timebins1<-substr( test.data_avgface_ADFES$timebins,1,3)

 View(simulated_clusters_Fear)
 View(sum_cluster_sim_ADFES)
simulattion_vs_data_ADFES<- left_join(sum_cluster_sim_ADFES, test.data_avgface_ADFES, by =
                                        c('timebins1'))
View(simulattion_vs_data_ADFES)


simulattion_vs_data_ADFES<- simulattion_vs_data_ADFES%>%
    ungroup()%>%
      # group_by(sim,Direction.y) %>%
  fill(MaxCLust_value.y, .direction = "down")%>%
  fill(MaxCLust_direction.y, .direction = "down")%>%
  # fill(MaxCLust_value.y, .direction = "down")%>%
  mutate(MAX_clust_count= if_else(is.na(MaxCLust_value.x) == TRUE,0, 
                                  if_else(abs(!is.na(MaxCLust_value.x))> abs(!is.na(MaxCLust_value.y)), 1, 0)))


# I think we need to take the clusters to columns (SPREAD)
# How many clusters did we have in the data
unique(simulattion_vs_data_ADFES$cluster_counter)
simulattion_vs_data_ADFES  <- simulattion_vs_data_ADFES %>%
  # group_by(cluster_counter)%>%
  mutate(cluster1_tsum = if_else(cluster_counter == 1, t_sum_dir, NULL))%>%
  mutate(cluster1_direction = if_else(cluster_counter == 1, MaxCLust_direction.y, NULL))%>%
  mutate(cluster2_tsum = if_else(cluster_counter == 2, t_sum_dir, NULL))%>%
  mutate(cluster2_direction = if_else(cluster_counter == 2, MaxCLust_direction.y, NULL))%>%
  mutate(cluster3_tsum = if_else(cluster_counter == 3, t_sum_dir, NULL))%>%
  mutate(cluster3_direction = if_else(cluster_counter == 3,MaxCLust_direction.y, NULL))%>%
  fill(cluster1_tsum, .direction = 'updown')%>%
  fill(cluster2_tsum, .direction = 'updown')%>%
  fill(cluster3_tsum, .direction = 'updown')%>%
  fill(cluster1_direction , .direction = 'updown')%>%
  fill(cluster2_direction , .direction = 'updown')%>%
  fill(cluster3_direction , .direction = 'updown')

View(simulattion_vs_data_ADFES)


unique(simulattion_vs_data$MAX_clust_count)
View(simulattion_vs_data_ADFES)
#  i think we need to tae the t value when the simulations are not significant
table(is.na(simulattion_vs_data_ADFES$t_sum_shuffle_dir))
 simulattion_vs_data_ADFES <-  simulattion_vs_data_ADFES %>%
   
  mutate(Max_clust_value_and_ns_t = if_else(is.na(t_sum_shuffle_dir), t.x, t_sum_shuffle_dir))%>%
  mutate(Max_clust_value_and_ns_t_jelka = t_sum_shuffle_dir)%>%
  mutate(Clust1_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster2_tsum), 1,0))%>%
  # mutate(Clust3_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t)> abs(cluster3_tsum), 1,0))%>%
   
  mutate(Clust1_sim_biggerthan_data1 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster1_tsum), 1,0))%>%
  mutate(Clust2_sim_biggerthan_data2 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster2_tsum), 1,0))%>%
  # mutate(Clust3_sim_biggerthan_data3 = if_else(abs(Max_clust_value_and_ns_t_jelka)> abs(cluster3_tsum), 1,0))%>%

  # mutate(Clust2_sim_biggerthan_data = if_else(abs(Max_clust_value_and_ns_t) > abs(cluster2_tsum), 1,0))%>%
  mutate(clust1_p =  sum(Clust1_sim_biggerthan_data)/n())%>%
  mutate(clust2_p =  sum(Clust2_sim_biggerthan_data)/n())%>%
  # mutate(clust3_p =  sum(Clust3_sim_biggerthan_data)/n())%>%
   
  mutate(clust1_p_jelka =  sum(Clust1_sim_biggerthan_data)/2001)%>%
  mutate(clust2_p_jelka =  sum(Clust2_sim_biggerthan_data)/2001)
  # mutate(clust3_p_jelka =  sum(Clust3_sim_biggerthan_data)/2001)
 # get p values
p_values_ADFES<- 
  simulattion_vs_data_ADFES %>%
  # subset(simulattion_vs_data_ADFES, is.na(as.factor(simulattion_vs_data_ADFES$cluster_counter)))%%
  group_by(cluster_counter)%>%
  summarise_at(c('clust1_p', 'clust2_p', 'clust3_p', 'clust1_p_jelka', 'clust2_p_jelka', 'clust3_p_jelka'), mean, na.rm = TRUE)

p_values_ADFES
test.data_avgface_ADFES<-left_join(test.data_avgface_ADFES, p_values_ADFES)


```



Disgust
```{r}
# db_of7_new$Emotion
db_of7_new_avg_Disgust<- subset(db_of7_new, db_of7_new$Emotion == "Disgust")



test.data_by_avg_Disgust<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Disgust<- unique(db_of7_new_avg_Disgust$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Disgust<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_avg_Disgust)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Disgust_results<- lmer(log1p(D1+.1) ~ VideoType_contrast + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Disgust[db_of7_new_avg_Disgust$timebin == timebin_avg_Disgust[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Disgust_results_sum<- summary(avg_Disgust_results)

   test.data_by_avg_Disgust[i,1]<-timebin_avg_Disgust[i]
   test.data_by_avg_Disgust[i,2]<- avg_Disgust_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Disgust[i,3]<- avg_Disgust_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Disgust[i,4]<- avg_Disgust_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Disgust_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Disgust$p_holm<- p.adjust(test.data_by_avg_Disgust$p, length(test.data_by_avg_Disgust$p), method = "holm")
 
 test.data_by_avg_Disgust$p_bonf<- p.adjust(test.data_by_avg_Disgust$p, length(test.data_by_avg_Disgust$p), 
                                          method ="bonf")
  View(test.data_by_avg_Disgust)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
test.data_by_avg_Disgust<- test.data_by_avg_Disgust%>%
  
  mutate(potent_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter>0, 0, 1))
  # p_clust<- test.data_by_avg_Disgust$
  
  View( test.data_by_avg_Disgust)
  
  

  
plots_of$avg_Disgust <- 
   test.data_by_avg_Disgust%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = potent_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+

     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red') +
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
   geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
      # scale_fill_viridis_c()+
     # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("Disgust")+
  xlab("Time (s)")+
  ylab("t statistic")
   
plots_of$avg_Disgust

plots_of$avg_Disgust <- plots_of$avg_Disgust +p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-2, 2, 6), limits = c(-2,6))
   
plots_of$avg_Disgust




```


Boostrap Disgust



```{r}
View(test.data_by_avg_Disgust)

test.data_by_avg_Disgust <- test.data_by_avg_Disgust %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Disgust$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Disgust)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Disgust<- test.data_by_avg_Disgust%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Disgust)
db_of7_new_avg_Disgust%>%
  # filter( Emotion == "Disgust")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Disgust%>%
  # filter(Emotion == "Disgust")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Disgust<- unique(db_of7_new_avg_Disgust$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Disgust<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Disgust)

# timebin_random_ADFES<- unique(db_of7_new_avg_Disgust$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Disgust$cov<- as.character( simulated_clusters_Disgust$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Disgust)
 
 db_of7_new_avg_Disgust$VideoType_contrast<- if_else(db_of7_new_avg_Disgust$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Disgust$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Disgust  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Disgust, db_of7_new_avg_Disgust$timebin == timebin_shuff_Disgust[b]))

        #store results from the somularion
            lmer_bin_random_summary_Disgust<- summary(lmer_bin_random_Disgust)
            simulated_clusters_Disgust[i,1]<- timebin_shuff_Disgust[b] #save the exact value of time bin
            simulated_clusters_Disgust[i,2]<- lmer_bin_random_summary_Disgust[["coefficients"]][2,1] # s
            simulated_clusters_Disgust[i,3]<-lmer_bin_random_summary_Disgust[["coefficients"]][2,4] # t statistic
            simulated_clusters_Disgust[i,4]<-lmer_bin_random_summary_Disgust[["coefficients"]][2,5] # p value
            simulated_clusters_Disgust[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Disgust[i,5] <-ifelse(length(lmer_bin_random_summary_Disgust$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Disgust$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}




```


Surprise
```{r}
# db_of7_new$Emotion
db_of7_new_avg_Surprise<- subset(db_of7_new, db_of7_new$Emotion == "Surprise")



test.data_by_avg_Surprise<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Surprise<- unique(db_of7_new_avg_Surprise$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Surprise<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2

for (i in 1:length(timebin_avg_Surprise)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Surprise_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Surprise[db_of7_new_avg_Surprise$timebin == timebin_avg_Surprise[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Surprise_results_sum<- summary(avg_Surprise_results)

   test.data_by_avg_Surprise[i,1]<-timebin_avg_Surprise[i]
   test.data_by_avg_Surprise[i,2]<- avg_Surprise_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Surprise[i,3]<- avg_Surprise_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Surprise[i,4]<- avg_Surprise_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Surprise_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Surprise$p_holm<- p.adjust(test.data_by_avg_Surprise$p, length(test.data_by_avg_Surprise$p), method = "holm")
 
 test.data_by_avg_Surprise$p_bonf<- p.adjust(test.data_by_avg_Surprise$p, length(test.data_by_avg_Surprise$p), 
                                          method ="bonf")
  View(test.data_by_avg_Surprise)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
  
  test.data_by_avg_Surprise<- test.data_by_avg_Surprise %>%
  mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))


plots_of$avg_Surprise <- 
   test.data_by_avg_Surprise%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      # scale_fill_viridis_c()+
  # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  ggtitle("Surprise")+
  xlab("Time (s)")+
  ylab("t statistic")
   
plots_of$avg_Surprise <- plots_of$avg_Surprise+ p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-6, 0, 6), limits = c(-6,6))

plots_of$avg_Surprise
```

Suprise Boostrap


```{r}
View(test.data_by_avg_Surprise)

test.data_by_avg_Surprise <- test.data_by_avg_Surprise %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Surprise$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Surprise)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Surprise<- test.data_by_avg_Surprise%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Surprise)
db_of7_new_avg_Surprise%>%
  # filter( Emotion == "Surprise")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Surprise%>%
  # filter(Emotion == "Surprise")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Surprise<- unique(db_of7_new_avg_Surprise$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Surprise<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Surprise)

# timebin_random_ADFES<- unique(db_of7_new_avg_Surprise$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Surprise$cov<- as.character( simulated_clusters_Surprise$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Surprise)
 
 db_of7_new_avg_Surprise$VideoType_contrast<- if_else(db_of7_new_avg_Surprise$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Surprise$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Surprise  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Surprise, db_of7_new_avg_Surprise$timebin == timebin_shuff_Surprise[b]))

        #store results from the somularion
            lmer_bin_random_summary_Surprise<- summary(lmer_bin_random_Surprise)
            simulated_clusters_Surprise[i,1]<- timebin_shuff_Surprise[b] #save the exact value of time bin
            simulated_clusters_Surprise[i,2]<- lmer_bin_random_summary_Surprise[["coefficients"]][2,1] # s
            simulated_clusters_Surprise[i,3]<-lmer_bin_random_summary_Surprise[["coefficients"]][2,4] # t statistic
            simulated_clusters_Surprise[i,4]<-lmer_bin_random_summary_Surprise[["coefficients"]][2,5] # p value
            simulated_clusters_Surprise[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Surprise[i,5] <-ifelse(length(lmer_bin_random_summary_Surprise$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Surprise$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}




```



Sadness

```{r}
# db_of7_new$Emotion
db_of7_new_avg_Sadness<- subset(db_of7_new, db_of7_new$Emotion == "Sadness")



test.data_by_avg_Sadness<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_avg_Sadness<- unique(db_of7_new_avg_Sadness$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_avg_Sadness<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_avg_Sadness)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  avg_Sadness_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique) + (1 | Dataset),
                      data = db_of7_new_avg_Sadness[db_of7_new_avg_Sadness$timebin == timebin_avg_Sadness[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  avg_Sadness_results_sum<- summary(avg_Sadness_results)

   test.data_by_avg_Sadness[i,1]<-timebin_avg_Sadness[i]
   test.data_by_avg_Sadness[i,2]<- avg_Sadness_results_sum[["coefficients"]][2,1]
   test.data_by_avg_Sadness[i,3]<- avg_Sadness_results_sum[["coefficients"]][2,4]
   test.data_by_avg_Sadness[i,4]<- avg_Sadness_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( avg_Sadness_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_avg_Sadness$p_holm<- p.adjust(test.data_by_avg_Sadness$p, length(test.data_by_avg_Sadness$p), method = "holm")
 
 test.data_by_avg_Sadness$p_bonf<- p.adjust(test.data_by_avg_Sadness$p, length(test.data_by_avg_Sadness$p), 
                                          method ="bonf")
  View(test.data_by_avg_Sadness)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$
  
  
  
test.data_by_avg_Sadness<- test.data_by_avg_Sadness %>%
  mutate(poten_clust = if_else(is.na(cluster_counter) == FALSE & cluster_counter > 0, 0,1))

plots_of$avg_Sadness <- 
   test.data_by_avg_Sadness%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =4.9 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = poten_clust),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_bonf), 
            alpha = 0.8)+

     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = 0, linetype = 'dashed', size = 1.5, colour = 'gray')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      # scale_fill_viridis_c()+
  # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
  ggtitle("Sadness")+
  xlab("Time (s)")+
  ylab("t statistic")
   
plots_of$avg_Sadness <- plots_of$avg_Sadness+ p$graphstyle+
  guides(fill = guide_colourbar(ticks = FALSE))+
  scale_y_continuous(breaks = c(-6, 0, 6), limits = c(-6,6))
   
plots_of$avg_Sadness




```


SadnessBoostrap

```{r}
View(test.data_by_avg_Sadness)

test.data_by_avg_Sadness <- test.data_by_avg_Sadness %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_avg_Sadness$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_avg_Sadness)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_avg_Sadness<- test.data_by_avg_Sadness%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_Sadness)
db_of7_new_avg_Sadness%>%
  # filter( Emotion == "Sadness")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_avg_Sadness%>%
  # filter(Emotion == "Sadness")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              

timebin_shuff_Sadness<- unique(db_of7_new_avg_Sadness$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_Sadness<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Sadness)

# timebin_random_ADFES<- unique(db_of7_new_avg_Sadness$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_Sadness$cov<- as.character( simulated_clusters_Sadness$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_avg_Sadness)
 
 db_of7_new_avg_Sadness$VideoType_contrast<- if_else(db_of7_new_avg_Sadness$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_avg_Sadness$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  640)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_Sadness  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_avg_Sadness, db_of7_new_avg_Sadness$timebin == timebin_shuff_Sadness[b]))

        #store results from the somularion
            lmer_bin_random_summary_Sadness<- summary(lmer_bin_random_Sadness)
            simulated_clusters_Sadness[i,1]<- timebin_shuff_Sadness[b] #save the exact value of time bin
            simulated_clusters_Sadness[i,2]<- lmer_bin_random_summary_Sadness[["coefficients"]][2,1] # s
            simulated_clusters_Sadness[i,3]<-lmer_bin_random_summary_Sadness[["coefficients"]][2,4] # t statistic
            simulated_clusters_Sadness[i,4]<-lmer_bin_random_summary_Sadness[["coefficients"]][2,5] # p value
            simulated_clusters_Sadness[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_Sadness[i,5] <-ifelse(length(lmer_bin_random_summary_Sadness$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Sadness$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}




```


Jeffe_emotions

Anger


```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Anger<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Anger")



test.data_by_JEFFE_avg_Anger<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Anger<- unique(db_of7_new_JEFFE_avg_Anger$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Anger<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_JEFFE_avg_Anger)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Anger_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Anger[db_of7_new_JEFFE_avg_Anger$timebin == timebin_JEFFE_avg_Anger[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Anger_results_sum<- summary(JEFFE_avg_Anger_results)

   test.data_by_JEFFE_avg_Anger[i,1]<-timebin_JEFFE_avg_Anger[i]
   test.data_by_JEFFE_avg_Anger[i,2]<- JEFFE_avg_Anger_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Anger[i,3]<- JEFFE_avg_Anger_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Anger[i,4]<- JEFFE_avg_Anger_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( JEFFE_avg_Anger_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_JEFFE_avg_Anger$p_holm<- p.adjust(test.data_by_JEFFE_avg_Anger$p, length(test.data_by_JEFFE_avg_Anger$p), method = "holm")
 
 test.data_by_JEFFE_avg_Anger$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Anger$p, length(test.data_by_JEFFE_avg_Anger$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Anger)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Anger <- 
   test.data_by_JEFFE_avg_Anger%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Anger")
   
plots_of$JEFFE_avg_Anger




```

JEFFE anger boostrap


```{r}
View(test.data_by_JEFFE_avg_Anger)

test.data_by_JEFFE_avg_Anger <- test.data_by_JEFFE_avg_Anger %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Anger$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Anger)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Anger<- test.data_by_JEFFE_avg_Anger%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Anger)
db_of7_new_JEFFE_avg_Anger%>%
  # filter( Emotion == "Anger")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Anger%>%
  # filter(Emotion == "Anger")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Anger<- unique(db_of7_new_JEFFE_avg_Anger$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Anger<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Anger)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Anger$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Anger$cov<- as.character( simulated_clusters_JEFFE_Anger$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Anger)
 
 db_of7_new_JEFFE_avg_Anger$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Anger$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Anger$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Anger  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Anger, db_of7_new_JEFFE_avg_Anger$timebin == timebin_shuff_JEFFE_Anger[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Anger<- summary(lmer_bin_random_JEFFE_Anger)
            simulated_clusters_JEFFE_Anger[i,1]<- timebin_shuff_Anger[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Anger[i,2]<- lmer_bin_random_summary_Anger[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Anger[i,3]<-lmer_bin_random_summary_Anger[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Anger[i,4]<-lmer_bin_random_summary_Anger[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Anger[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Anger[i,5]<-ifelse(length(lmer_bin_random_summary_Anger$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Anger$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}




```


Joy

```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Joy<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Joy")



test.data_by_JEFFE_avg_Joy<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Joy<- unique(db_of7_new_JEFFE_avg_Joy$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Joy<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_JEFFE_avg_Joy)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Joy_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Joy[db_of7_new_JEFFE_avg_Joy$timebin == timebin_JEFFE_avg_Joy[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Joy_results_sum<- summary(JEFFE_avg_Joy_results)

   test.data_by_JEFFE_avg_Joy[i,1]<-timestamp_JEFFE_avg_Joy[i]
   test.data_by_JEFFE_avg_Joy[i,2]<- JEFFE_avg_Joy_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Joy[i,3]<- JEFFE_avg_Joy_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Joy[i,4]<- JEFFE_avg_Joy_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( JEFFE_avg_Joy_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_JEFFE_avg_Joy$p_holm<- p.adjust(test.data_by_JEFFE_avg_Joy$p, length(test.data_by_JEFFE_avg_Joy$p), method = "holm")
 
 test.data_by_JEFFE_avg_Joy$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Joy$p, length(test.data_by_JEFFE_avg_Joy$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Joy)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Joy <- 
   test.data_by_JEFFE_avg_Joy%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      # scale_fill_viridis_c()+
   scale_fill_viridis_c(breaks= c(0, .5, 1), limits = c(0,1))+
     # scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Joy")
   
plots_of$JEFFE_avg_Joy





```

JOYE JEFFE boostrap
```{r}
View(test.data_by_JEFFE_avg_Joy)

test.data_by_JEFFE_avg_Joy <- test.data_by_JEFFE_avg_Joy %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Joy$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Joy)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Joy<- test.data_by_JEFFE_avg_Joy%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Joy)
db_of7_new_JEFFE_avg_Joy%>%
  # filter( Emotion == "Joy")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Joy%>%
  # filter(Emotion == "Joy")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Joy<- unique(db_of7_new_JEFFE_avg_Joy$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Joy<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Joy)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Joy$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Joy$cov<- as.character( simulated_clusters_JEFFE_Joy$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Joy)
 
 db_of7_new_JEFFE_avg_Joy$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Joy$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Joy$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Joy  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Joy, db_of7_new_JEFFE_avg_Joy$timebin == timebin_shuff_JEFFE_Joy[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Joy<- summary(lmer_bin_random_JEFFE_Joy)
            simulated_clusters_JEFFE_Joy[i,1]<- timebin_shuff_Joy[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Joy[i,2]<- lmer_bin_random_summary_Joy[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Joy[i,3]<-lmer_bin_random_summary_Joy[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Joy[i,4]<-lmer_bin_random_summary_Joy[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Joy[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Joy[i,5]<-ifelse(length(lmer_bin_random_summary_Joy$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Joy$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}

```



Sadness
```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Sadness<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Sadness")



test.data_by_JEFFE_avg_Sadness<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Sadness<- unique(db_of7_new_JEFFE_avg_Sadness$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Sadness<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_JEFFE_avg_Sadness)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Sadness_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Sadness[db_of7_new_JEFFE_avg_Sadness$timebin == timebin_JEFFE_avg_Sadness[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Sadness_results_sum<- summary(JEFFE_avg_Sadness_results)

   test.data_by_JEFFE_avg_Sadness[i,1]<-timebin_JEFFE_avg_Sadness[i]
   test.data_by_JEFFE_avg_Sadness[i,2]<- JEFFE_avg_Sadness_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Sadness[i,3]<- JEFFE_avg_Sadness_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Sadness[i,4]<- JEFFE_avg_Sadness_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( JEFFE_avg_Sadness_results)
 # test.data_bySurprise1<- test.data_bySurprise
test.data_by_JEFFE_avg_Sadness$p_holm<- p.adjust(test.data_by_JEFFE_avg_Sadness$p, length(test.data_by_JEFFE_avg_Sadness$p), method = "holm")
 
 test.data_by_JEFFE_avg_Sadness$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Sadness$p, length(test.data_by_JEFFE_avg_Sadness$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Sadness)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Sadness <- 
   test.data_by_JEFFE_avg_Sadness%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Sadness")
   
plots_of$JEFFE_avg_Sadness



```


Sadness boostrap

```{r}
View(test.data_by_JEFFE_avg_Sadness)

test.data_by_JEFFE_avg_Sadness <- test.data_by_JEFFE_avg_Sadness %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Sadness$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Sadness)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Sadness<- test.data_by_JEFFE_avg_Sadness%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Sadness)
db_of7_new_JEFFE_avg_Sadness%>%
  # filter( Emotion == "Sadness")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Sadness%>%
  # filter(Emotion == "Sadness")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Sadness<- unique(db_of7_new_JEFFE_avg_Sadness$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check
seed(444)
#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Sadness<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_JEFFE_Sadness)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Sadness$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Sadness$cov<- as.character( simulated_clusters_JEFFE_Sadness$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Sadness)
 
 db_of7_new_JEFFE_avg_Sadness$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Sadness$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Sadness$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Sadness  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Sadness, db_of7_new_JEFFE_avg_Sadness$timebin == timebin_shuff_JEFFE_Sadness[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Sadness<- summary(lmer_bin_random_JEFFE_Sadness)
            simulated_clusters_JEFFE_Sadness[i,1]<- timebin_shuff_Sadness[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Sadness[i,2]<- lmer_bin_random_summary_Sadness[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Sadness[i,3]<-lmer_bin_random_summary_Sadness[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Sadness[i,4]<-lmer_bin_random_summary_Sadness[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Sadness[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Sadness[i,5]<-ifelse(length(lmer_bin_random_summary_Sadness$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Sadness$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}

```


Fear

```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Fear<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Fear")



test.data_by_JEFFE_avg_Fear<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Fear<- unique(db_of7_new_JEFFE_avg_Fear$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Fear<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_JEFFE_avg_Fear)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Fear_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Fear[db_of7_new_JEFFE_avg_Fear$timebin == timebin_JEFFE_avg_Fear[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Fear_results_sum<- summary(JEFFE_avg_Fear_results)

   test.data_by_JEFFE_avg_Fear[i,1]<-timestamp_JEFFE_avg_Fear[i]
   test.data_by_JEFFE_avg_Fear[i,2]<- JEFFE_avg_Fear_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Fear[i,3]<- JEFFE_avg_Fear_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Fear[i,4]<- JEFFE_avg_Fear_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( JEFFE_avg_Fear_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_JEFFE_avg_Fear$p_holm<- p.adjust(test.data_by_JEFFE_avg_Fear$p, length(test.data_by_JEFFE_avg_Fear$p), method = "holm")
 
 test.data_by_JEFFE_avg_Fear$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Fear$p, length(test.data_by_JEFFE_avg_Fear$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Fear)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Fear <- 
   test.data_by_JEFFE_avg_Fear%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Fear")
   
plots_of$JEFFE_avg_Fear



```



Fear JEFFE boostrap

```{r}

View(test.data_by_JEFFE_avg_Fear)

test.data_by_JEFFE_avg_Fear <- test.data_by_JEFFE_avg_Fear %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Fear$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Fear)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Fear<- test.data_by_JEFFE_avg_Fear%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Fear)
db_of7_new_JEFFE_avg_Fear%>%
  # filter( Emotion == "Fear")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Fear%>%
  # filter(Emotion == "Fear")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Fear<- unique(db_of7_new_JEFFE_avg_Fear$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check
seed(444)
#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Fear<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_JEFFE_Fear)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Fear$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Fear$cov<- as.character( simulated_clusters_JEFFE_Fear$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Fear)
 
 db_of7_new_JEFFE_avg_Fear$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Fear$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Fear$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Fear  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Fear, db_of7_new_JEFFE_avg_Fear$timebin == timebin_shuff_JEFFE_Fear[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Fear<- summary(lmer_bin_random_JEFFE_Fear)
            simulated_clusters_JEFFE_Fear[i,1]<- timebin_shuff_Fear[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Fear[i,2]<- lmer_bin_random_summary_Fear[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Fear[i,3]<-lmer_bin_random_summary_Fear[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Fear[i,4]<-lmer_bin_random_summary_Fear[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Fear[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Fear[i,5]<-ifelse(length(lmer_bin_random_summary_Fear$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Fear$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}





```

Disgust
```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Disgust<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Disgust")



test.data_by_JEFFE_avg_Disgust<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Disgust<- unique(db_of7_new_JEFFE_avg_Disgust$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Disgust<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_JEFFE_avg_Disgust)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Disgust_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Disgust[db_of7_new_JEFFE_avg_Disgust$timebin == timebin_JEFFE_avg_Disgust[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Disgust_results_sum<- summary(JEFFE_avg_Disgust_results)

   test.data_by_JEFFE_avg_Disgust[i,1]<-timebin_JEFFE_avg_Disgust[i]
   test.data_by_JEFFE_avg_Disgust[i,2]<- JEFFE_avg_Disgust_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Disgust[i,3]<- JEFFE_avg_Disgust_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Disgust[i,4]<- JEFFE_avg_Disgust_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}

summary( JEFFE_avg_Disgust_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_JEFFE_avg_Disgust$p_holm<- p.adjust(test.data_by_JEFFE_avg_Disgust$p, length(test.data_by_JEFFE_avg_Disgust$p), method = "holm")
 
 test.data_by_JEFFE_avg_Disgust$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Disgust$p, length(test.data_by_JEFFE_avg_Disgust$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Disgust)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Disgust <- 
   test.data_by_JEFFE_avg_Disgust%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Disgust")
   
plots_of$JEFFE_avg_Disgust





```


View(test.data_by_JEFFE_avg_Sadness)

```{r}
test.data_by_JEFFE_avg_Disgust <- test.data_by_JEFFE_avg_Disgust %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Disgust$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Disgust)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Disgust<- test.data_by_JEFFE_avg_Disgust%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Disgust)
db_of7_new_JEFFE_avg_Disgust%>%
  # filter( Emotion == "Disgust")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Disgust%>%
  # filter(Emotion == "Disgust")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Disgust<- unique(db_of7_new_JEFFE_avg_Disgust$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check
seed(444)
#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Disgust<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_JEFFE_Disgust)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Disgust$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Disgust$cov<- as.character( simulated_clusters_JEFFE_Disgust$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Disgust)
 
 db_of7_new_JEFFE_avg_Disgust$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Disgust$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Disgust$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Disgust  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Disgust, db_of7_new_JEFFE_avg_Disgust$timebin == timebin_shuff_JEFFE_Disgust[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Disgust<- summary(lmer_bin_random_JEFFE_Disgust)
            simulated_clusters_JEFFE_Disgust[i,1]<- timebin_shuff_Disgust[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Disgust[i,2]<- lmer_bin_random_summary_Disgust[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Disgust[i,3]<-lmer_bin_random_summary_Disgust[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Disgust[i,4]<-lmer_bin_random_summary_Disgust[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Disgust[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Disgust[i,5]<-ifelse(length(lmer_bin_random_summary_Disgust$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Disgust$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}
```
Surprise

```{r}
# db_of7_new$Emotion
db_of7_new_JEFFE_avg_Surprise<- subset(db_of7_new, db_of7_new$Dataset == "JEFFE" & db_of7_new$Emotion == "Surprise")



test.data_by_JEFFE_avg_Surprise<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_JEFFE_avg_Surprise<- unique(db_of7_new_JEFFE_avg_Surprise$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_JEFFE_avg_Surprise<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_JEFFE_avg_Surprise)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  JEFFE_avg_Surprise_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_JEFFE_avg_Surprise[db_of7_new_JEFFE_avg_Surprise$timebin == timebin_JEFFE_avg_Surprise[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  JEFFE_avg_Surprise_results_sum<- summary(JEFFE_avg_Surprise_results)

   test.data_by_JEFFE_avg_Surprise[i,1]<-timebin_JEFFE_avg_Surprise[i]
   test.data_by_JEFFE_avg_Surprise[i,2]<- JEFFE_avg_Surprise_results_sum[["coefficients"]][2,1]
   test.data_by_JEFFE_avg_Surprise[i,3]<- JEFFE_avg_Surprise_results_sum[["coefficients"]][2,4]
   test.data_by_JEFFE_avg_Surprise[i,4]<- JEFFE_avg_Surprise_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( JEFFE_avg_Surprise_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_JEFFE_avg_Surprise$p_holm<- p.adjust(test.data_by_JEFFE_avg_Surprise$p, length(test.data_by_JEFFE_avg_Surprise$p), method = "holm")
 
 test.data_by_JEFFE_avg_Surprise$p_bonf<- p.adjust(test.data_by_JEFFE_avg_Surprise$p, length(test.data_by_JEFFE_avg_Surprise$p), 
                                          method ="bonf")
  View(test.data_by_JEFFE_avg_Surprise)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$JEFFE_avg_Surprise <- 
   test.data_by_JEFFE_avg_Surprise%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("JEFFE AVG face motion ~ Morph - Surprise")
   
plots_of$JEFFE_avg_Surprise




```


View(test.data_by_JEFFE_avg_Sadness)
```{r}
test.data_by_JEFFE_avg_Surprise <- test.data_by_JEFFE_avg_Surprise %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_JEFFE_avg_Surprise$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_JEFFE_avg_Surprise)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_JEFFE_avg_Surprise<- test.data_by_JEFFE_avg_Surprise%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_JEFFE_Surprise)
db_of7_new_JEFFE_avg_Surprise%>%
  # filter( Emotion == "Surprise")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_JEFFE_avg_Surprise%>%
  # filter(Emotion == "Surprise")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_JEFFE_Surprise<- unique(db_of7_new_JEFFE_avg_Surprise$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check
seed(444)
#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_JEFFE_Surprise<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_JEFFE_Surprise)

# timebin_random_ADFES<- unique(db_of7_new_JEFFE_avg_Surprise$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_JEFFE_Surprise$cov<- as.character( simulated_clusters_JEFFE_Surprise$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_JEFFE_avg_Surprise)
 
 db_of7_new_JEFFE_avg_Surprise$VideoType_contrast<- if_else(db_of7_new_JEFFE_avg_Surprise$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_JEFFE_avg_Surprise$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_JEFFE_Surprise  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_JEFFE_avg_Surprise, db_of7_new_JEFFE_avg_Surprise$timebin == timebin_shuff_JEFFE_Surprise[b]))

        #store results from the somularion
            lmer_bin_random_summary_JEFFE_Surprise<- summary(lmer_bin_random_JEFFE_Surprise)
            simulated_clusters_JEFFE_Surprise[i,1]<- timebin_shuff_Surprise[b] #save the exact value of time bin
            simulated_clusters_JEFFE_Surprise[i,2]<- lmer_bin_random_summary_Surprise[["coefficients"]][2,1] # s
            simulated_clusters_JEFFE_Surprise[i,3]<-lmer_bin_random_summary_Surprise[["coefficients"]][2,4] # t statistic
            simulated_clusters_JEFFE_Surprise[i,4]<-lmer_bin_random_summary_Surprise[["coefficients"]][2,5] # p value
           simulated_clusters_JEFFE_Surprise[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_JEFFE_Surprise[i,5]<-ifelse(length(lmer_bin_random_summary_Surprise$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Surprise$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}

```

ADFES emotion
Anger


```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Anger<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Anger")



test.data_by_ADFES_avg_Anger<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timebin_ADFES_avg_Anger<- unique(db_of7_new_ADFES_avg_Anger$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Anger<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timebin_ADFES_avg_Anger)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Anger_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Anger[db_of7_new_ADFES_avg_Anger$timebin == timebin_ADFES_avg_Anger[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Anger_results_sum<- summary(ADFES_avg_Anger_results)

   test.data_by_ADFES_avg_Anger[i,1]<-timestamp_ADFES_avg_Anger[i]
   test.data_by_ADFES_avg_Anger[i,2]<- ADFES_avg_Anger_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Anger[i,3]<- ADFES_avg_Anger_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Anger[i,4]<- ADFES_avg_Anger_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Anger_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Anger$p_holm<- p.adjust(test.data_by_ADFES_avg_Anger$p, length(test.data_by_ADFES_avg_Anger$p), method = "holm")
 
 test.data_by_ADFES_avg_Anger$p_bonf<- p.adjust(test.data_by_ADFES_avg_Anger$p, length(test.data_by_ADFES_avg_Anger$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Anger)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Anger <- 
   test.data_by_ADFES_avg_Anger%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Anger")
   
plots_of$ADFES_avg_Anger




```

```{r}
View(test.data_by_ADFES_avg_Anger)

test.data_by_ADFES_avg_Anger <- test.data_by_ADFES_avg_Anger %>%
  ungroup()%>%
  mutate(cluster_log = if_else(test.data_by_ADFES_avg_Anger$p< .05, TRUE, FALSE))%>%
  mutate(Direction = if_else(t > 0 & cluster_log == TRUE, "Positive", 
                             if_else(t < 0 & cluster_log == TRUE, "Negative", NULL)))%>% # flag direction that is
        # group_by(sim)%>%
        mutate(idx = !is.na(Direction))%>%
        mutate(cluster_counter  = as.numeric(replace(Direction, idx, rleid(rleid(Direction)[idx]))))%>%
      # create a cluster t sum by adjacency, remeber the up there we grouped 
      # cluster counter shuffle makes sure ajancent significant bisn are griuped together
      # direction - do we need thisDirection, cluster_shuffle_log 
      group_by(cluster_counter)%>%
      mutate(t_sum_dir = sum(t))%>%
      # ungroup()%>%
      mutate(t_sum_dir = if_else(cluster_log == TRUE, t_sum_dir, NULL))%>% #summ timebins into clusters statistics
        # create max cluster lavels, store the direction value of the cluster and the label of the direction
      # suppressWarnings
        # group_by(sim)%>%
      mutate(MaxCLust_label = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE),
                                      cluster_counter, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_value = if_else(abs(t_sum_dir) == max(abs(t_sum_dir), na.rm = TRUE), 
                                      t_sum_dir, NULL ))%>%
      # suppressWarnings
      mutate(MaxCLust_direction = if_else(MaxCLust_value > 0, "Positive", "Negative"))
View(test.data_by_ADFES_avg_Anger)
# negative estmate = morph has less actiation
        
library(data.table)
# create a counter for helpting with cluster by adjancecy

# regular corrections
# test.data_by_ADFES_avg_Anger<- test.data_by_ADFES_avg_Anger%>%
#   mutate(p_bonf = p.adjust(p, method = 'holm'))%>%
#   mutate(p_holm = p.adjust(p, method = "bonf"))


# go back to the data use to fit - db_of7_new[db_of7_new$timestamp == timebinout_avg[i],])
nrow(db_of7_new_avg_ADFES_Anger)
db_of7_new_ADFES_avg_Anger%>%
  # filter( Emotion == "Anger")%>%
  group_by(morph)%>%
  summarise(n = n())# 1280/2



i = 1

View(testtemp)

db_of7_new_ADFES_avg_Anger%>%
  # filter(Emotion == "Anger")%>%
  group_by(video, morph)%>%
  summarise(time = mean(timebin, na.rm = TRUE))%>%
  group_by(morph)%>%
  summarise(n = n()) # collapsing time now we have 16 vidoe per videotype
              
timebin_shuff_ADFES_Anger<- unique(db_of7_new_ADFES_avg_Anger$timebin)

 # create a random arrangment of labels for oroginal and morpj

nsim = 1:1000 #no. of simullation
nbins  =1:40 # numbr of bins. aways check

#create an empty dataframe to store results of the simulation
# remeber to always define it before simulation

simulated_clusters_ADFES_Anger<- data.frame(timebins= rep(NA, max(nsim)*max(nbins)), Estimate= rep(NA, max(nsim)*max(nbins)), t=rep(NA, max(nsim)*max(nbins)), p=rep(NA, max(nsim)*max(nbins)), cov= as.character(rep(NA,max(nsim)*max(nbins))), sim = rep(NA, max(nsim)*max(nbins)) )

View(simulated_clusters_Anger)

# timebin_random_ADFES<- unique(db_of7_new_ADFES_avg_Anger$timebin)

# create random labels

i = 1 # remember to always rezero it
# b = 34

seed = 444

simulated_clusters_ADFES_Anger$cov<- as.character( simulated_clusters_ADFES_Anger$cov) # remeber to run

 i = 1
 # b = 1
 # s = 1
 
 View(db_of7_new_ADFES_avg_Anger)
 
 db_of7_new_ADFES_avg_Anger$VideoType_contrast<- if_else(db_of7_new_ADFES_avg_Anger$morph == "Morph", -.5, .5) # morph == -.5, original .5

 i = 1

for (b in 1:length(nbins)) {
  for (s in 1:length(nsim)) {

    message(sprintf("$$$$$RUNING simulation %i & bin %i", nsim[s], nbins[b]))
    db_of7_new_ADFES_avg_Anger$VideoType_contrast_sample<- sample((rep(c(-.5, .5), each =  320)), replace = FALSE) 
        #run the model on the current time bin and simulation sumber
        lmer_bin_random_ADFES_Anger  <- lmer(log1p(face_action_AVG +.1) ~ VideoType_contrast_sample + 
                                   (1 |face_unique),
                      data = subset(db_of7_new_ADFES_avg_Anger, db_of7_new_ADFES_avg_Anger$timebin == timebin_shuff_ADFES_Anger[b]))

        #store results from the somularion
            lmer_bin_random_summary_ADFES_Anger<- summary(lmer_bin_random_ADFES_Anger)
            simulated_clusters_ADFES_Anger[i,1]<- timebin_shuff_Anger[b] #save the exact value of time bin
            simulated_clusters_ADFES_Anger[i,2]<- lmer_bin_random_summary_Anger[["coefficients"]][2,1] # s
            simulated_clusters_ADFES_Anger[i,3]<-lmer_bin_random_summary_Anger[["coefficients"]][2,4] # t statistic
            simulated_clusters_ADFES_Anger[i,4]<-lmer_bin_random_summary_Anger[["coefficients"]][2,5] # p value
           simulated_clusters_ADFES_Anger[i,6]<- nsim[s] #store simulation ount
            simulated_clusters_ADFES_Anger[i,5]<-ifelse(length(lmer_bin_random_summary_Anger$optinfo$conv$lme4$message)
                                                   != 0,
                                               lmer_bin_random_summary_Anger$optinfo$conv$lme4$message, 'pass')

     i = i+1
  }
}

```





Joy

```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Joy<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Joy")



test.data_by_ADFES_avg_Joy<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timestamp_ADFES_avg_Joy<- unique(db_of7_new_ADFES_avg_Joy$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Joy<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_ADFES_avg_Joy)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Joy_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Joy[db_of7_new_ADFES_avg_Joy$timebin == timestamp_ADFES_avg_Joy[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Joy_results_sum<- summary(ADFES_avg_Joy_results)

   test.data_by_ADFES_avg_Joy[i,1]<-timestamp_ADFES_avg_Joy[i]
   test.data_by_ADFES_avg_Joy[i,2]<- ADFES_avg_Joy_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Joy[i,3]<- ADFES_avg_Joy_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Joy[i,4]<- ADFES_avg_Joy_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Joy_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Joy$p_holm<- p.adjust(test.data_by_ADFES_avg_Joy$p, length(test.data_by_ADFES_avg_Joy$p), method = "holm")
 
 test.data_by_ADFES_avg_Joy$p_bonf<- p.adjust(test.data_by_ADFES_avg_Joy$p, length(test.data_by_ADFES_avg_Joy$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Joy)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Joy <- 
   test.data_by_ADFES_avg_Joy%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Joy")
   
plots_of$ADFES_avg_Joy





```
Sadness
```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Sadness<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Sadness")



test.data_by_ADFES_avg_Sadness<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timestamp_ADFES_avg_Sadness<- unique(db_of7_new_ADFES_avg_Sadness$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Sadness<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_ADFES_avg_Sadness)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Sadness_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Sadness[db_of7_new_ADFES_avg_Sadness$timebin == timestamp_ADFES_avg_Sadness[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Sadness_results_sum<- summary(ADFES_avg_Sadness_results)

   test.data_by_ADFES_avg_Sadness[i,1]<-timestamp_ADFES_avg_Sadness[i]
   test.data_by_ADFES_avg_Sadness[i,2]<- ADFES_avg_Sadness_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Sadness[i,3]<- ADFES_avg_Sadness_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Sadness[i,4]<- ADFES_avg_Sadness_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Sadness_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Sadness$p_holm<- p.adjust(test.data_by_ADFES_avg_Sadness$p, length(test.data_by_ADFES_avg_Sadness$p), method = "holm")
 
 test.data_by_ADFES_avg_Sadness$p_bonf<- p.adjust(test.data_by_ADFES_avg_Sadness$p, length(test.data_by_ADFES_avg_Sadness$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Sadness)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Sadness <- 
   test.data_by_ADFES_avg_Sadness%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Sadness")
   
plots_of$ADFES_avg_Sadness



```


Fear

```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Fear<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Fear")



test.data_by_ADFES_avg_Fear<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timestamp_ADFES_avg_Fear<- unique(db_of7_new_ADFES_avg_Fear$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Fear<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_ADFES_avg_Fear)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Fear_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Fear[db_of7_new_ADFES_avg_Fear$timebin == timestamp_ADFES_avg_Fear[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Fear_results_sum<- summary(ADFES_avg_Fear_results)

   test.data_by_ADFES_avg_Fear[i,1]<-timestamp_ADFES_avg_Fear[i]
   test.data_by_ADFES_avg_Fear[i,2]<- ADFES_avg_Fear_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Fear[i,3]<- ADFES_avg_Fear_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Fear[i,4]<- ADFES_avg_Fear_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Fear_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Fear$p_holm<- p.adjust(test.data_by_ADFES_avg_Fear$p, length(test.data_by_ADFES_avg_Fear$p), method = "holm")
 
 test.data_by_ADFES_avg_Fear$p_bonf<- p.adjust(test.data_by_ADFES_avg_Fear$p, length(test.data_by_ADFES_avg_Fear$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Fear)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Fear <- 
   test.data_by_ADFES_avg_Fear%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Fear")
   
plots_of$ADFES_avg_Fear



```

Disgust
```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Disgust<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Disgust")



test.data_by_ADFES_avg_Disgust<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timestamp_ADFES_avg_Disgust<- unique(db_of7_new_ADFES_avg_Disgust$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Disgust<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_ADFES_avg_Disgust)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Disgust_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Disgust[db_of7_new_ADFES_avg_Disgust$timebin == timestamp_ADFES_avg_Disgust[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Disgust_results_sum<- summary(ADFES_avg_Disgust_results)

   test.data_by_ADFES_avg_Disgust[i,1]<-timestamp_ADFES_avg_Disgust[i]
   test.data_by_ADFES_avg_Disgust[i,2]<- ADFES_avg_Disgust_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Disgust[i,3]<- ADFES_avg_Disgust_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Disgust[i,4]<- ADFES_avg_Disgust_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Disgust_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Disgust$p_holm<- p.adjust(test.data_by_ADFES_avg_Disgust$p, length(test.data_by_ADFES_avg_Disgust$p), method = "holm")
 
 test.data_by_ADFES_avg_Disgust$p_bonf<- p.adjust(test.data_by_ADFES_avg_Disgust$p, length(test.data_by_ADFES_avg_Disgust$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Disgust)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Disgust <- 
   test.data_by_ADFES_avg_Disgust%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Disgust")
   
plots_of$ADFES_avg_Disgust





```


Surprise

```{r}
# db_of7_new$Emotion
db_of7_new_ADFES_avg_Surprise<- subset(db_of7_new, db_of7_new$Dataset == "ADFES" & db_of7_new$Emotion == "Surprise")



test.data_by_ADFES_avg_Surprise<- data.frame(timebins= rep(NA, 40), Estimate= rep(NA, 40), t=rep(NA, 40), p=rep(NA, 40), cov= as.character(rep(NA,40)) )

timestamp_ADFES_avg_Surprise<- unique(db_of7_new_ADFES_avg_Surprise$timebin)
# test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults_ADFES_avg_Surprise<- list()
# lmer


# currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore


i = 2
for (i in 1:length(timestamp_ADFES_avg_Surprise)) {
  # Surprise_results<- t.test(log1p(D1+.1) ~ morph,var.equal = FALSE, paired = FALSE, data = db_of7_new[db_of7_new$timestamp == timebinout[i],])
  ADFES_avg_Surprise_results<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of7_new_ADFES_avg_Surprise[db_of7_new_ADFES_avg_Surprise$timebin == timestamp_ADFES_avg_Surprise[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of7_new [db_of7_new$timebin == timebinout[i] & db_of7_new$Dataset !="ADFES",])
  ADFES_avg_Surprise_results_sum<- summary(ADFES_avg_Surprise_results)

   test.data_by_ADFES_avg_Surprise[i,1]<-timestamp_ADFES_avg_Surprise[i]
   test.data_by_ADFES_avg_Surprise[i,2]<- ADFES_avg_Surprise_results_sum[["coefficients"]][2,1]
   test.data_by_ADFES_avg_Surprise[i,3]<- ADFES_avg_Surprise_results_sum[["coefficients"]][2,4]
   test.data_by_ADFES_avg_Surprise[i,4]<- ADFES_avg_Surprise_results_sum[["coefficients"]][2,5]
  #
   
   
  #     test.data_bySurprise[i,1]<-timestamp_Surprise[i]
  # # test.data_bySurprise[i,2]<- Surprise_results_sum[["coefficients"]][2,1]
  #  test.data_bySurprise[i,3]<- Surprise_results$statistic
  #  test.data_bySurprise[i,4]<- Surprise_results$p.value
  #  # test.data[i,5]<- testresults@optinfo$val
   print(i)
}
summary( ADFES_avg_Surprise_results)
 # test.data_bySurprise1<- test.data_bySurprise
 test.data_by_ADFES_avg_Surprise$p_holm<- p.adjust(test.data_by_ADFES_avg_Surprise$p, length(test.data_by_ADFES_avg_Surprise$p), method = "holm")
 
 test.data_by_ADFES_avg_Surprise$p_bonf<- p.adjust(test.data_by_ADFES_avg_Surprise$p, length(test.data_by_ADFES_avg_Surprise$p), 
                                          method ="bonf")
  View(test.data_by_ADFES_avg_Surprise)
# now sum adjancet timebins
  # testresults@optinfo$conv$opt$

plots_of$ADFES_avg_Surprise <- 
   test.data_by_ADFES_avg_Surprise%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.7 , ymax =6 , fill = p_bonf),
            alpha = 0.8)+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.3 , ymax =5.6 , fill = p_holm), 
            alpha = 0.8)+
   geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5 , ymax =5.2 , fill = p), 
            alpha = 0.8)+
     geom_hline(yintercept = 2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
  geom_hline(yintercept = -2, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     # ylim(1,6)+
      scale_fill_viridis_c()+
     scale_colour_gradient2(mid = "white", limits = c(0,1), midpoint = .5)+
  ggtitle("ADFES AVG face motion ~ Morph - Surprise")
   
plots_of$ADFES_avg_Surprise




```


seems lie d2, d4, d8, d7 don't show string correlations with one another or d1


zanes paper (D2, D3, D4, D6, D7, and D8)



CHECK THIS PACKAGE
```{R}
     
  install.packages("permuco")
  library(permuco)

  
clusterlm(
  formula = D1 ~  morph*(face_unique/(morph)),
    # morph + (1| face_unique),
  data = db_of8,
  np = 50,
  multcomp = "clustermass")

method = NULL,
  test = "fisher",
  threshold = 2,
  # aggr_FUN = NULL,
  
```


# create an empty dataframe that will fold the information from each test
test.data<- data.frame(timebins= rep(NA, 150), Estimate= rep(NA, 150), t=rep(NA, 150), p=rep(NA, 150), cov= as.character(rep(NA,150)) )
test.data$timebinout<- as.vector(timebinout) # add the curerent timebins to that vector

# empty list of test results
testresults<- list()
# lmer


i = 15 # currently we have 15 time bins
# the loop below does
# 1 - goes from element i ina  list of eleements 1 to the last time bind_cols
# 2- runs a lmer model regresing face distance to morph vs original, while controling for intercepts of dataset and intercept of unique faces
#3 - stores the result of the model
#4- store informatio on the bin tested, the coeficients, p values and t tests
# morph variance is almost zerp
# dtaset is highly correleted, so ignore

i = 2


for (i in 1:length(timebinout)) {
  testresults<- lmer(log1p(D1+.1) ~ morph + (1 |face_unique),
                      data = db_of8[db_of8$timestamp == timebinout[i],])

  # testresults<- lmer(log1p(D1+.1) ~ morph + (1|face_unique),
  #                     data = db_of8 [db_of8$timebin == timebinout[i] & db_of8$Dataset !="JEFFE",])
   summarytest<- summary(testresults)
   
   test.data[i,1]<-timebinout[i]
   test.data[i,2]<-summarytest[["coefficients"]][2,1]
   test.data[i,3]<-summarytest[["coefficients"]][2,4]
   test.data[i,4]<-summarytest[["coefficients"]][2,5]
   # test.data[i,5]<- testresults@optinfo$val
   print("")
   }

summary(testresults)


# now sum adjancet timebins



  # testresults@optinfo$conv$opt$


# check a few of the warning messages
# do multiple comparison tests
  test.data$p_cor<-   .05/15
  test.data$p_bonf<- if_else(test.data$p> test.data$p_cor, "NS", "p<.01")

   test.data%>%
     ggplot(aes(as.numeric(timebins), t))+
     geom_rect(aes(xmin = timebins, xmax = dplyr::lead(timebins), ymin =5.5 , ymax =6 , fill = p_bonf), 
            alpha = 0.3)+
     geom_hline(yintercept = 3, linetype = 'dashed', size = 1.5, colour = 'red')+
     stat_summary(geom = 'line', size = 2)+
               theme_classic()+
     ylim(1,6)

     scale_color_brewer(palette = 'Red2')
  # ylim(380, 400)+
  facet_grid(~Dataset)
   




```


summarytest$<- summary(testresults)

 summarytest[["coefficients"]][1,2]
for (i in timebinout) {
  testresults[i]<- t.test(subset(db_of8, db_of8$timebin == timebinout[i])$D1 ~ (subset(db_of8, db_of8$timebin == timebinout[i])$VideoType_contrast, alt="two.sided", paired = TRUE, conf.level = 0.99))

timebinout[i]
}

  polymodels$tst@beta
```


  # Speed
  # let's compute speed
db_of2<- db_of2%>%
  group_by(video)%>%
  mutate(speed = abs(D1- lead(D1))/abs(timestamp-lag(timestamp)))%>%
  mutate(acceleration = (speed- lag(speed))/abs(timestamp-lag(timestamp)))%>%
  mutate(peak_speed = max(speed, na.rm = TRUE))%>%
  mutate(peak_acc = max(abs(acceleration), na.rm = TRUE))
  # filter(video == 'F02_Anger_ADFES_Original')%>%
  # ggplot(aes(timestamp, acceleration))+
  # geom_line()
  
  
  
  
# For pixel levels(eyes <-  mutate(D2 = sqrt((x_21-x_22)^2+ (y_21-y_22)^2))%>%
# nose<- sqrt((x_27-x_31)^2+(x_27-x_35)^2+ (x_31-x_35)^2+(y_27-y_31)^2)+(y_27-y_35)^2+
#   (y_31-y_35)^2)%>%
#   
#   
# Mouth
# sqrt((x_27-x_50)^2+(x_27-x_52)^2+(x_50-x_52)^2+(y_27-y_50)^2+(y_27-y_52)^2+(y_50-y_52)^2))%>%)
  



```



```





db_of3<- db_of2 %>%
  group_by(video, Dataset, Emotion, morph)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)
write_csv(db_of3, 'db_of3.csv')


test4<- db_of3
test2$intensity_morph<- NULL
rownames(test4) <- db_of3$Video
test4$Video<- NULL
colnames(db_of3)
test4<- select(test4, c(4:8))

test4$Dataset<- NULL
test4$Emotion<- NULL
test4$D9<- NULL
rownames(test4) <- test4$video

test4$video<- NULL
clust2 <- eclust(test4, "kmeans",
                 nstart = 25, graph = TRUE, k = 4)

```{r}
clust2$cluster
clust2$clust_plot
fviz_cluster(clust2$clust_plot,  frame.type = "norm", frame.level = 0.9)
lmeanplot


```



```{r}
# assumotions for t test
ggqqplot(cm_adf_bind$dif,
         ggtheme = theme_minimal())

ggqqplot(cm_adf_bind$Prop1,
         ggtheme = theme_minimal())

shapiro.test(cm_adf_bind$dif) # => p-value = 0.6993

 z<-df %>%
 arrange(time1) %>%
 group_by(time1) %>%
 do(tidy(t.test(df$sbp,df$sbp1,paired=TRUE))) 


cm_adf_bind%>%
  group_by(comb)%>%
  do(tidy(t.test(cm_adf_bind$dif,paired=FALSE))) 

  t_test(dif ~ comb, mu = 0)

View(cm_adf_bind)
prop.table(cm_adf_morph$table)
db_april_task2_adfes_morph$countpreref<- paste0(db_april_task2_adfes_morph$Prediction, paste0(db_april_task2_adfes_morph$Reference))

db_april_task2_adfes_morph%>%
  group_by(Emotion)%>%
  summarise(count = n())

```


```{r}
# correlations
install.packages('DescTools')
library( DescTools)


# # NOT RUN {
# cors <- seq(-.9, .9, .1)
# # Fisher to z
# zs <- FisherZ(cors)
# rs <- FisherZInv(zs)
# round(zs, 2)
# n <- 30
# r <- seq(0, .9, .1)
# rc <- t(sapply(r, CorCI, n=n))
# t <- r * sqrt(n-2) / sqrt(1-r^2)
# p <- (1 - pt(t, n-2)) / 2
# 
# r.rc <- data.frame(r=r, z=FisherZ(r), lower=rc[,2], upper=rc[,3], t=t, p=p)
# 
# round(r.rc,2)
# }

db_april_task2_cor<- subset(db_april_task2, db_april_task2$AttentionCheckCorrectSum_Valence>2 &
                                db_april_task2$Mental_health == 'no')



db_april_task2_cor<- db_april_task2_cor %>%
  group_by(ParticipantPrivateID, DATASET, VideoType) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)


# db_april_task2_agg1<- db_april_task2_agg %>%
#   group_by(ParticipantPrivateID, VideoType, DATASET)%>%
#   summarise_at(c('Recognacc'), mean, na.rm = TRUE)

db_april_task2_agg1_morph<- subset(db_april_task2_cor,db_april_task2_cor$VideoType == 'Morph')
db_april_task2_agg1_origi<- subset(db_april_task2_cor,db_april_task2_cor$VideoType != 'Morph')

View(db_april_task2_agg1_morph)

db_april_task2_agg1_for_cor<- left_join(db_april_task2_agg1_morph, db_april_task2_agg1_origi, by = c("ParticipantPrivateID", "DATASET"))

db_april_task2_agg1_for_cor<- db_april_task2_agg1_for_cor%>%
  group_by(ParticipantPrivateID, DATASET)%>%
  summarise_at(c('Recognacc.x', 'Recognacc.y'), mean, na.rm = TRUE)
  

db_april_task2_agg1_for_cor %>%
  ggplot(aes(Recognacc.x, Recognacc.y))+
  geom_point(aes(colour = DATASET))+
  geom_smooth(method = 'lm')+
  facet_grid(~DATASET)
  
```

```{r}
test<- subset(db_april_task2_agg1_for_cor, db_april_task2_agg1_for_cor$DATASET == ADFES)
db_april_task2_agg1_for_cor%>%
  ungroup(-ParticipantPrivateID)%>%
  # group_by(DATASET)%>%
  summarise(cor = cor(Recognacc.y, Recognacc.x))
  # mutate(z =FisherZ(cor) )%>%
  # mutate(z1 = FisherZInv(z))%>%
  mutate(f_z =  CorCI(cor, n = 96, conf.level = 0.95, alternative = c("two.sided")))

FisherZ(rho)
FisherZInv(z)
CorCI(rho, n, conf.level = 0.95, alternative = c("two.sided", "less", "greater"))

db_april_task2_agg1_for_cor%>%
  group_by(DATASET)%>%
  summarise(n = n())

# by data set
db_april_task2_agg1_adfes<- subset(db_april_task2_cor,db_april_task2_cor$DATASET == 'ADFES')
db_april_task2_agg1_jeffe<- subset(db_april_task2_cor,db_april_task2_cor$DATASET != 'ADFES')

db_april_task2_agg1_for_cor1<- left_join(db_april_task2_agg1_adfes, db_april_task2_agg1_jeffe, by = c("ParticipantPrivateID", "VideoType"))
db_april_task2_agg1_for_cor1.1<- db_april_task2_agg1_for_cor1%>%
  group_by(ParticipantPrivateID, VideoType)%>%
  summarise_at(c('Recognacc.x', 'Recognacc.y'), mean, na.rm = TRUE)

# test<-left_join(subset(db_april_task2_agg1_for_cor1.1, db_april_task2_agg1_for_cor1.1$VideoType == 'Morph'), subset(db_april_task2_agg1_for_cor1.1, db_april_task2_agg1_for_cor1.1$VideoType == 'Original'), by = 'ParticipantPrivateID')

View(test)

cor(test$Recognacc.y.x, test$Recognacc.y.y)

db_april_task2_agg1_for_cor1.1%>%
  ggplot(aes(Recognacc.x, Recognacc.y))+
  geom_point()+
  geom_smooth(method = 'lm')


```

export
```{r}

db_april_task2$comb<- paste0(db_april_task2$DATASET,paste0(db_april_task2$VideoType, paste0(db_april_task2$Video)))
db_april_task2_A<- subset(db_april_task2, db_april_task2$Block =="block12")
db_april_task2_B<- subset(db_april_task2, db_april_task2$Block =="block34")


db_april_task2_wide_A<- dcast(setDT(db_april_task2_A), ParticipantPrivateID ~ comb, value.var = c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality", "Recognacc"), fun.aggregate = mean, na.rm = TRUE)
View(db2_A_wide)

db_april_task2_B_wide<- dcast(setDT(db_april_task2_B), ParticipantPrivateID ~ comb, value.var = c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality", "Recognacc"), fun.aggregate = mean, na.rm = TRUE)
View(db2_B_wide)

write_csv(db_april_task2_wide_A, 'db_april_task2_wide_A.csv')
write_csv(db_april_task2_B_wide, 'db_april_task2_B_wide.csv')



View(db_april_task2_wide_A)

a<- t(db_april_task2_wide_A)
a<- as.data.frame(a)
View(a)

library(data.table)
setDT(a, keep.rownames = TRUE)[]
setDT(a, keep.colnames = TRUE)[]


header.true <- function(df) {
  names(df) <- as.character(unlist(df[1,]))
  df[-1,]
}

as.character(unlist(a[0,]))

header.true(a)

names(a) <- as.matrix(a[1, ])
a <- a[-1, ]
a[] <- lapply(a, function(x) type.convert(as.character(x)))
a$variables<- a$ParticipantPrivateID
a$ParticipantPrivateID<-NULL

write_csv(a, 'a.csv')
colnames(a)
a<-select(a, c(55, 1:54))

a$variables

a$variableclusters<- if_else(grepl("JEFFEOriginal", a$variables), 'JEFFEOriginal',
                        if_else(grepl("ADFESOriginal", a$variables), 'ADFESOriginal', 
                                if_else(grepl("JEFFEMorph", a$variables), 'JEFFEMorph',
                        if_else(grepl("ADFESMorph", a$variables), 'ADFESMorph', NULL)))) 


a$valence<- if_else(grepl('Valence', a$variables), TRUE, FALSE)

a_valence<- subset(a, a$valence == TRUE)
write_csv(a_valence1, 'a_v.csv')


a_valence%>%
  group_by(variables)
colnames(a_valence)
a_valence1<- transform(a_valence, col4= rowMeans(a_valence[,2:55], na.rm = TRUE))
```

Clustering


- Clustering (the ) do items video ids cluster differently,
- wr need dimenson to cluster by (features) is this valence, ietsity ratings etc? since we are interested in cluster of items, we probably need to aggregate participants in the featires (mean) - beacsue participants are not features, and add a column for database and 

```{r}
db_april_task_cluster<- db_april_task2

db_april_task_cluster$comb<- paste0(db_april_task_cluster$DATASET,paste0(db_april_task_cluster$VideoType, paste0(db_april_task_cluster$Video)))
```


export
```{r}

library(data.table)
db_april_task_cluster_wide<- dcast(setDT(db_april_task_cluster), ParticipantPrivateID ~ comb, value.var = c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality", "Recognacc"), fun.aggregate = mean, na.rm = TRUE)
View(db_april_task_cluster)

View(db_april_task_cluster_wide)

db_april_task_cluster1<- db_april_task_cluster %>%
  group_by(Video, intensity_morph)%>%
  summarise_at(c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality"), mean, na.rm = TRUE)

write.csv(db_april_task_cluster1, 'db_april_task_cluster.csv')

db_april_task2_B_wide<- dcast(setDT(db_april_task2_B), ParticipantPrivateID ~ comb, value.var = c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality", "Recognacc"), fun.aggregate = mean, na.rm = TRUE)
View(db2_B_wide)

write_csv(db_april_task2_wide_A, 'db_april_task2_wide_A.csv')
write_csv(db_april_task2_B_wide, 'db_april_task2_B_wide.csv')

install.packages('factoextra')
library("factoextra")

# K-means clustering
View(db_april_task_cluster1)
factoextra::eclust()
kmeans<- factoextra::eclust(db_april_task_cluster1[,2:4], "kmeans", k = 4)

test<- as.matrix(db_april_task_cluster1)
rownames(db_april_task_cluster1) <- db_april_task_cluster1$Video
kmeans
head(db_april_task_cluster1)

View(db_april_task_cluster1)
test<- db_april_task_cluster1

test1<- subset(test, grepl('ADFES', test$Video) == FALSE)

test2<- subset(test, grepl('ADFES', test$Video) == TRUE)

test
test1$intensity_morph<- NULL
View(test1)
rownames(test1) <- test1$Video
test1$Video<- NULL

db_april_task_cluster1$clus<- if_else(grepl('Morph', db_april_task_cluster1$Video, 'Moprh', 'Original'))


test1<- scale(test1)

head(test)
km.res <- eclust(test1, "kmeans", k = 2,
                 nstart = 25, graph = FALSE)

lmeanplot<-fviz_cluster(km.res,  frame.type = "norm", frame.level = 0.9)
lmeanplot
ggsave("lmeanplot2.jpg", device = 'png',dpi = 300, width = 25, height = 18)


test2$intensity_morph<- NULL
rownames(test2) <- test2$Video
test2$Video<- NULL

clust2 <- eclust(test2, "kmeans",
                 nstart = 25, graph = FALSE)

fviz_cluster(clust2,  frame.type = "norm", frame.level = 0.9)
lmeanplot

test


```


To do
include autistic data,

combine it with old data and compare


```{r}
library(readr)
db_ASC <- read_csv("~/Documents/FaceDynamics/FaceDynamics/cleaned_data_withAT.csv")
View(db_ASC)


# subset the task only

db_ASC_task<- subset(db_ASC, db_ASC$display == 'Task')


db_ASC_task$ZoneType<- NULL

# keep participnat on
db_ASC_task<- db_ASC_task[,2:ncol(db_ASC_task)]

```

```{r}
library(dplyr)
View(db_ASC_task)
colnames(db_ASC_task)

colnames(db1)
db_ASC_task <- select(db_ASC_task, c(1:10,14:16))

```


```{r}
## use set FT from data table otherwise it won't accept dcsting to mulyiple variables, whatever is next to ~ is the column that we want to dcast for mutiple columns

library(data.table)
View(db_ASC_task)
colnames(db_ASC)


# store dataset name
db_ASC_task$DATASET<- substr(db_ASC_task$DATASETS, 1, 5)

db_ASC_task$Block<- ifelse(db_ASC_task$`randomiser-dafk` == "block12", 'A', 'B')


# dcast separete rating to different columns
db_ASC_task2<- dcast(setDT(db_ASC_task), ParticipantPrivateID + Block+ Video+Emotion+DATASETS + VideoType ~ ScreenName, value.var = c("AnswerRating", "ReactionTime"))

View(db_ASC_task2)

# Create means for ratings
# do we need to group by aricipants?
db_ASC_task2<- db_ASC_task2 %>%
  group_by(Video)%>%
  mutate(Recognacc = if_else(AnswerRating_Recognition == Emotion, 1,0))%>%
  mutate(valence_mean = mean(as.numeric(AnswerRating_Valence), na.rm = TRUE))%>%
  mutate(intensity_mean = mean(as.numeric(AnswerRating_Intensity), na.rm = TRUE))%>%
  mutate(natural_mean = mean(as.numeric(AnswerRating_Naturality), na.rm = TRUE))%>%
  mutate(valence_rtmean = mean(as.numeric(ReactionTime_Valence), na.rm = TRUE))%>%
  mutate(intensity_rtmean = mean(as.numeric(ReactionTime_Intensity), na.rm = TRUE))%>%
  mutate(natural_rtmean = mean(as.numeric(ReactionTime_Naturality), na.rm = TRUE))%>%
  mutate(recignition_mean = (sum(Recognacc)/n()))%>%
  mutate(recognition_rtmean = mean(as.numeric(ReactionTime_Recognition), na.rm = TRUE))


# make sure our variables are specified with the correct type
str(db2)

db_ASC_task2$DATASET<-substr(db_ASC_task2$DATASETS, 1,5)

db_ASC_task2$uniquestimid<- substr(db_ASC_task2$Video, 1,7)


#morph by dataset
db_ASC_task2$intensity_morph<- paste0(db_ASC_task2$DATASETS, paste0(db_ASC_task2$VideoType))
unique(db_ASC_task2$intensity_morph)


db_ASC_task3 <- db_ASC_task2 %>%
  mutate(ParticipantPrivateID = as.factor(as.character(ParticipantPrivateID)))%>%
  #mutate(Video = as.factor(Video))%>%
  mutate(Emotion = as.factor(as.character(Emotion)))%>%
  mutate(DATASETS = as.factor(as.character(DATASETS)))%>%
  mutate(DATASET = as.factor(as.character(DATASET)))%>%
  mutate(VideoType = as.factor(as.character(VideoType)))%>%
  mutate(AnswerRating_Intensity = as.numeric(as.character(AnswerRating_Intensity)))%>%
  mutate(AnswerRating_Naturality = as.numeric(as.character(AnswerRating_Naturality)))%>%
  mutate(AnswerRating_Valence = as.numeric(as.character(AnswerRating_Valence)))%>%
  mutate(uniquestimid = as.factor(as.character(uniquestimid)))%>%
  mutate(intensity_morph = as.factor(as.character(intensity_morph)))


View(db_ASC_task3)

  

# db_ASC_task4<- dcast(setDT(db_ASC_task3), ParticipantPrivateID + Video+Emotion+DATASETS~VideoType , 
#             value.var = c('Recognacc'))


```


# preliminary visualisations

```{r}
db_ASC_task3$DATASET
db_ASC_task3$VideoType

db_ASC_task3 %>%
  ggplot(aes(VideoType, AnswerRating_Valence))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')



db_ASC_task3 %>%
  ggplot(aes(VideoType, AnswerRating_Intensity))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)


db_ASC_task3 %>%
  ggplot(aes(VideoType, AnswerRating_Naturality))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)


db_ASC_task3 %>%
  ggplot(aes(VideoType, Recognacc))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)
db_ASC_task3$Group<- "ASC"



 db_april_task2$Group <- "NT"

 db_april_task2 %>%
  ggplot(aes(VideoType, Recognacc))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)

# merge datasets
db_ASC_NT<- bind_rows(db_ASC_task3,  db_april_task2)

#accuracy
db_ASC_NT%>%
  ggplot(aes(VideoType, Recognacc, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')
  #facet_grid(~DATASET)

db_ASC_NT%>%
  ggplot(aes(VideoType, Recognacc, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)

# intensity
db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Intensity, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')



# Valence

db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Valence, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')

db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Valence, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)


# naturality
db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Naturality, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')

db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Naturality, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(~DATASET)



db_ASC_NT%>%
  group_by(Group, ParticipantPrivateID)%>%
  summarise(n = mean(Recognacc))
  


```

Initial visualisations ASC vs NT

- Recognition, ASC underforms in both sets, both sets have a hit in emotion recognition accuracy
- - the effect seems to be the same in both datasets
- Intemsity - ASC rates morhs oerall as less intense, same direction of effcect for both groups, no particular effects of database
- Valence, no differences between the groups, thre does seem to be and ffect of dataset
- naturality - morhs are overall judged as less natural, but this effects is biger in ASC whreas it doesnt seem to reach significance in NT based on error bars. there does seem to be a significant intecation for dataset.


Now let's look at the same thing for emotions

```{r}
#accuracy
db_ASC_NT%>%
  ggplot(aes(VideoType, Recognacc, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
 facet_grid(DATASET~Emotion)
 
```


```{r}
# intensity
db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Intensity, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(DATASET~Emotion)


```

```{r}
# Valence
db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Valence, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(DATASET~Emotion)


```



```{r}
# naturality
db_ASC_NT %>%
  ggplot(aes(VideoType, AnswerRating_Naturality, colour = Group))+
  #geom_jitter(width = .2, alpha = .2)+
  stat_summary(geom = 'errorbar')+
  facet_grid(DATASET~Emotion)
```
Overall the global effects show up in separae emotions to some degree



Let's see the confusion patterns


```{r}
db_ASC_NT%>%
  group_by(ParticipantPrivateID,Group,  Emotion, DATASET, VideoType, AnswerRating_Recognition)%>%
  summarise_at(c('Recognacc', 'AnswerRating_Naturality', 'AnswerRating_Intensity', 'AnswerRating_Valence'),mean, na.rm = TRUE)%>%
  ggplot(aes(Emotion, AnswerRating_Recognition, fill = AnswerRating_Intensity))+
  geom_tile()+
  facet_grid(VideoType~ Group)


```

```{r}

db_ASC_NT$Reference<- db_ASC_NT$Emotion
db_ASC_NT$Prediction <- db_ASC_NT$AnswerRating_Recognition


library(caret)
# add nn extra neutral on emotion/actual

# union would allow us to add and extra category in emotion


a1<- union(db_ASC_NT$Prediction, db_ASC_NT$Reference)



db_ASC_ADF_Confusion_Orig<- subset(db_ASC_NT, db_ASC_NT$intensity_morph == 'ADFES_high_intensityOriginal' & db_ASC_NT$Group == 'ASC')

db_ASC_ADF_Confusion_Orig

# confusion

db_ASC_ADF_Confusion_Orig_matrix <- caret::confusionMatrix(table(factor(db_ASC_ADF_Confusion_Orig$Reference, a1), factor(db_ASC_ADF_Confusion_Orig$Prediction, a1)))

# table

db_ASC_ADF_Confusion_Orig_table<- as.data.frame(db_ASC_ADF_Confusion_Orig_matrix$table)
db_ASC_ADF_Confusion_Orig_table$Prop <- db_ASC_ADF_Confusion_Orig_table$Freq/56 #divide the total by 6?


b1
ggplot(db_ASC_ADF_Confusion_Orig_table, aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red",limit = c(0,1), space = "Lab", 
                       name="Pearson\nCorrelation")



# Let's start with morph vs non morph
db_ASC_Morph<- subset(db_ASC_NT, db_ASC_NT$VideoType == "Morph" & db_ASC_NT$Group == 'ASC')


a1<- union(db_ASC_NT$Prediction, db_ASC_NT$Reference)

# Morph confusionMatrix()
# confusion

db_ASC_Morph_confusionMatrix <- caret::confusionMatrix(table(factor(db_ASC_Morph$Reference, a1), factor(db_ASC_Morph$Prediction, a1)))


# table

db_ASC_Morph_Confusion_table<- as.data.frame(db_ASC_Morph_confusionMatrix$table)
db_ASC_Morph_Confusion_table$Prop <- db_ASC_Morph_Confusion_table$Freq/111 #divide the total by 6?

sum(db_ASC_Morph_Confusion_table$Freq)/6

db_ASC_Morph_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red", space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")


# NT

# Let's start with morph vs non morph
db_NT_Morph<- subset(db_ASC_NT, db_ASC_NT$VideoType == "Morph" & db_ASC_NT$Group == 'NT')


a1<- union(db_ASC_NT$Prediction, db_ASC_NT$Reference)

# Morph confusionMatrix()
# confusion

db_NT_Morph_confusionMatrix <- caret::confusionMatrix(table(factor(db_NT_Morph$Reference, a1), factor(db_NT_Morph$Prediction, a1)))


# table

db_NT_Morph_Confusion_table<- as.data.frame(db_NT_Morph_confusionMatrix$table)
db_NT_Morph_Confusion_table$Prop <- db_NT_Morph_Confusion_table$Freq/848 #divide the total by 6?

sum(db_NT_Morph_Confusion_table$Freq)/6

db_NT_Morph_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red", limits = c(0,1),space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")

db_ASC_Morph_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red",limits = c(0,1),  space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")
  geom_text(aes(label=Prop)) 
  
  
  db_NT_Morph_Confusion_table%>%
    filter(Var1 != Var2)
  
  
   db_ASC_Morph_Confusion_table%>%
    filter(Var1 != Var2)
    summarise(cor)







```
  
  


Original
```{r}
# Let's start with Original vs non Original
db_ASC_Original<- subset(db_ASC_NT, db_ASC_NT$VideoType == "Original" & db_ASC_NT$Group == 'ASC')


a<- union(db_ASC_NT$Prediction, db_ASC_NT$Reference)

# Original confusionMatrix()
# confusion

db_ASC_Original_confusionMatrix <- caret::confusionMatrix(table(factor(db_ASC_Original$Reference, a1), factor(db_ASC_Original$Prediction, a1)))


# table

db_ASC_Original_Confusion_table<- as.data.frame(db_ASC_Original_confusionMatrix$table)
db_ASC_Original_Confusion_table$Prop <- db_ASC_Original_Confusion_table$Freq/111 #divide the total by 6?

sum(db_ASC_Original_Confusion_table$Freq)/6

db_ASC_Original_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red", space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")


# NT

# Let's start with Original vs non Original
db_NT_Original<- subset(db_ASC_NT, db_ASC_NT$VideoType == "Original" & db_ASC_NT$Group == 'NT')


a1<- union(db_ASC_NT$Prediction, db_ASC_NT$Reference)

# Original confusionMatrix()
# confusion

db_NT_Original_confusionMatrix <- caret::confusionMatrix(table(factor(db_NT_Original$Reference, a1), factor(db_NT_Original$Prediction, a1)))


# table

db_NT_Original_Confusion_table<- as.data.frame(db_NT_Original_confusionMatrix$table)
db_NT_Original_Confusion_table$Prop <- db_NT_Original_Confusion_table$Freq/848 #divide the total by 6?

sum(db_NT_Original_Confusion_table$Freq)/6

db_NT_Original_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red", limits = c(0,1),space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")

db_ASC_Original_Confusion_table%>%
  ggplot(aes(Var1, Var2, fill = Prop))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red",limits = c(0,1),  space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")
  geom_text(aes(label=Prop)) 
  
  
  
left_join(db_ASC_Original_Confusion_table,db_ASC_Morph_Confusion_table, by = c("Var1", "Var2")) %>%
  ggplot(aes(Var1, Var2, fill = abs(Prop.x - Prop.y)))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red",  space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")


left_join(db_NT_Original_Confusion_table,db_NT_Morph_Confusion_table, by = c("Var1", "Var2")) %>%
  ggplot(aes(Var1, Var2, fill = abs(Prop.x - Prop.y)))+
  geom_tile()+
  scale_color_viridis_c(palette = 'Inferno')+
  theme_minimal()+  scale_fill_gradient2(low = "blue", high = "red",   space = "Lab", 
                       name="Pearson\nCorrelation")+
  xlab("Emotion")+
  ylab("Response")



limits = c(0,1),


unique(db_ASC$ParticipantPrivateID)
```
  

Is there a correlatin bewteen performance by stimuli. are stimuli that are ore accurate in in one also accurate in another set?

```{r}
db_ASC_NT%>%
  group_by(uniquestimid, VideoType, Group)%>%
  summarise_if(is.numeric,mean, na.rm = TRUE)%>%
  ggplot(aes(VideoType, Recognacc))+
  geom_jitter()+
  geom_smooth(aes(group = uniquestimid),method = 'lm', se = F)+
  facet_grid(~Group)




```


What about participants 

is participants perfromance conistence across tasks
```{r}
db_ASC_NT%>%
  group_by(ParticipantPrivateID, VideoType, Group)%>%
  summarise_if(is.numeric,mean, na.rm = TRUE)%>%
  ggplot(aes(VideoType, Recognacc))+
  geom_jitter()+
  geom_smooth(aes(group = ParticipantPrivateID),method = 'lm', se = F)+
  facet_grid(~Group)
  


```

try scatters

```{r}

left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group")) %>%
  group_by(ParticipantPrivateID, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(Recognacc.x, Recognacc.y))+
  geom_point()+
  facet_grid(~Group)+
  geom_smooth(method = "lm")

left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group")) %>%
  group_by(uniquestimid, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(Recognacc.x, Recognacc.y))+
  geom_point()+
  facet_grid(~Group)+
  geom_smooth(method = "lm")



left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group", "Emotion")) %>%
  group_by(uniquestimid, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(AnswerRating_Intensity.x, AnswerRating_Intensity.y))+
  geom_point()+
  facet_grid(~Group)+
  geom_smooth(method = "lm")
  
  
left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group", "Emotion")) %>%
  group_by(uniquestimid, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(AnswerRating_Valence.x, AnswerRating_Valence.y))+
  geom_point()+
  facet_grid(~Group)+
  geom_smooth(method = "lm")


left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group", "Emotion")) %>%
  group_by(uniquestimid, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(AnswerRating_Naturality.x, AnswerRating_Naturality.y))+
  geom_point()+
  facet_grid(~Group)+
  geom_smooth(method = "lm")



left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group", "Emotion", "DATASET")) %>%
  group_by(uniquestimid, Group, DATASET)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(AnswerRating_Naturality.x, AnswerRating_Naturality.y))+
  geom_point()+
  facet_grid(DATASET~Group)+
  geom_smooth(method = "lm")


left_join(db_ASC_NT[db_ASC_NT$VideoType == "Morph"], db_ASC_NT[db_ASC_NT$VideoType != "Morph"], 
          by =c('ParticipantPrivateID', 'uniquestimid', "Group", "Emotion", "DATASET")) %>%
  group_by(uniquestimid, Group, DATASET)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)%>%
  ggplot(aes(Recognacc.x, Recognacc.y))+
  geom_point()+
  facet_grid(DATASET~Group)+
  geom_smooth(method = "lm")




    

```


There is a strong correlation between perfoemance in morp and performance in originals when collapsing stimuli set
- Participants who are good in one tend ti be good in the other
- Trials where people form well tend to be the same stimuli that leads to better performance in both tasks
this holds for intensity,valence and naturality
- 



Let's try one full model


```{r}
library(lmerTest)
full_models<- list()
db_ASC_NT
full_models$null<- lmer(AnswerRating_Intensity ~  (1 + Emotion+DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)


relgrad <- with(full_models$null@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))



summary(full_models$null)


full_models$main_effs1<- lmer(AnswerRating_Intensity ~ VideoType+ Group+ Emotion +  (1 + Emotion+DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)

relgrad <- with(full_models$main_effs1@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))


full_models$int_effs2<- lmer(AnswerRating_Intensity ~ VideoType * Group* Emotion +  (1 + Emotion+DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)

relgrad <- with(full_models$int_effs2@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

summary(full_models$int_effs2)

summary(full_models$main_effs)


full_models$main_effs4<- lmer(log1p(AnswerRating_Intensity+.1) ~ VideoType + Group + DATASET + Emotion+  (1 + DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)

plot(full_models$main_effs4)


relgrad <- with(full_models$main_effs4@optinfo$derivs,solve(Hessian,gradient))
max(abs(relgrad))

summary(full_models$main_effs4)

anova(full_models$main_effs4, refit = TRUE, 'LRT')
step(full_models$main_effs4)


full_models$int_effs4<- lmer(AnswerRating_Intensity ~ VideoType + Group + (1 + DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)


plot(full_models$main_effs4)

qqnorm(resid(full_models$main_effs4))
qqline(resid(full_models$main_effs4))



# boostrap
install.packages("robustlmm")
library(robustlmm) 
# takes forever

# robust sicne it doesn't meet assumptions let's try boostrap

full_models$main_effs4<- lmer(log1p(AnswerRating_Intensity+.1) ~ VideoType + Group + DATASET + Emotion+  (1 + DATASET | ParticipantPrivateID) + (1| Video), REML =
                          FALSE,
                        data = db_ASC_NT, verbose = TRUE)
?bootMer

#Parametric bootstrap with 2000 iterations
bootImpChange<-bootMer(x=modelsImpressionChange$full, FUN=fixef, nsim=2000, seed = 444, use.u = FALSE, type=“parametric”)
summary(bootImpChange) #Bias estimates


full_models$main_effs4_boot <- bootMer(full_models$main_effs4,FUN = fixef,  nsim = 500, seed = 444, use.u = FALSE,
                                      type="parametric")

summary(full_models$main_effs4_boot)

#Bootstrapped CI for the parameters - Reported in the appendix
boot::boot.ci(full_models$main_effs4_boot,type="perc",index=2)
boot::boot.ci(full_models$main_effs4_boot,type="perc",index=3)
boot::boot.ci(full_models$main_effs4_boot,type="perc",index=4)


summary(full_models$int_effs4)


summary(full_models$int_effs4)
anova(full_models$main_effs4, full_models$int_effs4)


anova(full_models$int_effs4)



# logistic models
full_models$acc_null<- glmer(Recognacc ~ (1 + DATASET | ParticipantPrivateID) + (1| Video), 
                        data = db_ASC_NT, verbose = TRUE)

summary(full_models$acc_null)

full_models$acc_maineffs<- glmer(Recognacc ~ VideoType + Group + Emotion +DATASET+ (1 + DATASET | ParticipantPrivateID) + (1| Video), 
                        data = db_ASC_NT, verbose = TRUE)

summary(full_models$acc_maineffs)

anova(full_models$acc_maineffs)



```




clusters based on ASD vs NT
```{r}

db_ASC_NT_wide<- dcast(setDT(db_ASC_NT), ParticipantPrivateID + Group ~ VideoType, value.var = c("AnswerRating_Valence","AnswerRating_Intensity", "AnswerRating_Naturality", "Recognacc"), fun.aggregate = mean, na.rm = TRUE)
View(db_ASC_NT_wide)

write.csv(db_ASC_NT, "db_ASC_NT.csv")


db_ASC_NT_agg<- db_ASC_NT_wide%>%
  group_by(ParticipantPrivateID, Group)%>%
  summarise_if(is.numeric, mean, na.rm = TRUE)


write.csv(db_ASC_NT_agg, "db_ASC_NT_agg.csv")

```

  db_NT_Original_Confusion_table%>%
    filter(Var1 != Var2)
  
  
   db_ASC_Original_Confusion_table%>%
    filter(Var1 != Var2)
    summarise(cor)





```


View(db_april_task2_wide_A)

a<- t(db_april_task2_wide_A)
a<- as.data.frame(a)
View(a)

library(data.table)
setDT(a, keep.rownames = TRUE)[]
setDT(a, keep.colnames = TRUE)[]


header.true <- function(df) {
  names(df) <- as.character(unlist(df[1,]))
  df[-1,]
}

as.character(unlist(a[0,]))

header.true(a)

names(a) <- as.matrix(a[1, ])
a <- a[-1, ]
a[] <- lapply(a, function(x) type.convert(as.character(x)))
a$variables<- a$ParticipantPrivateID
a$ParticipantPrivateID<-NULL

write_csv(a, 'a.csv')
colnames(a)
a<-select(a, c(55, 1:54))

a$variables

a$variableclusters<- if_else(grepl("JEFFEOriginal", a$variables), 'JEFFEOriginal',
                        if_else(grepl("ADFESOriginal", a$variables), 'ADFESOriginal', 
                                if_else(grepl("JEFFEMorph", a$variables), 'JEFFEMorph',
                        if_else(grepl("ADFESMorph", a$variables), 'ADFESMorph', NULL)))) 


a$valence<- if_else(grepl('Valence', a$variables), TRUE, FALSE)

a_valence<- subset(a, a$valence == TRUE)
write_csv(a_valence1, 'a_v.csv')


a_valence%>%
  group_by(variables)
colnames(a_valence)
a_valence1<- transform(a_valence, col4= rowMeans(a_valence[,2:55], na.rm = TRUE))
